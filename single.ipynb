{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from go_ai import policies, game, metrics, data\n",
    "from go_ai.models import value_model\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 256\n",
    "NUM_EVAL_GAMES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TEMP = 1/64\n",
    "TEMP_DECAY = 3/4\n",
    "MIN_TEMP = 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8pWCj8jGa7Y"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODELS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES_DIR = 'episodes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfJcqNeEGa7b"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/checkpoint_{}x{}.pt'.format(BOARD_SIZE, BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_TRAJECTORY_PATH = 'logs/a_trajectory.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4m-C0k6Ga7q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueNet(\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(6, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_model = value_model.ValueNet(BOARD_SIZE)\n",
    "checkpoint_model = value_model.ValueNet(BOARD_SIZE)\n",
    "\n",
    "if LOAD_SAVED_MODELS:\n",
    "    assert os.path.exists(CHECKPOINT_PATH)\n",
    "    print(\"Starting from checkpoint\")\n",
    "else:\n",
    "    torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "    print(\"Initialized checkpoint\") \n",
    "\n",
    "curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "\n",
    "optim = torch.optim.Adam(curr_model.parameters(), 1e-3)\n",
    "curr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_policy = policies.QTempPolicy('Current', curr_model, INIT_TEMP)\n",
    "checkpoint_policy = policies.QTempPolicy('Checkpoint', checkpoint_model, INIT_TEMP)\n",
    "\n",
    "random_policy = policies.RandomPolicy()\n",
    "greedy_policy = policies.QTempPolicy('Greedy', policies.greedy_val_func, temp=0)\n",
    "human_policy = policies.HumanPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_temps(policies, temp_decay, min_temp):\n",
    "    for policy in policies:\n",
    "        assert hasattr(policy, 'temp')\n",
    "        policy.temp *= temp_decay\n",
    "        if policy.temp < min_temp:\n",
    "            policy.temp = min_temp\n",
    "        print(f\"{policy.name} temp decayed to {policy.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVCEKWx_Ga7r"
   },
   "source": [
    "# Demo and Time Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSQ1RFHuGa7r"
   },
   "source": [
    "Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 28.2 ms, total: 352 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "action = (1, 1)\n",
    "next_state, _, _, _ = go_env.step(action)\n",
    "metrics.plot_symmetries(next_state, 'logs/symmetries.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 675 ms, sys: 65.1 ms, total: 741 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "_,_ = game.pit(go_env, curr_policy, curr_policy, get_traj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrTjrYjBGa7u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.4 s, sys: 126 ms, total: 3.53 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "outputId": "100dda95-316e-457c-b1f3-c8bf82243c52",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:02<00:00,  2.09it/s, 46.1%]\n",
      "Optimizing: 182it [00:28,  6.40it/s, 82.8%, 0.381L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:14<00:00,  1.90it/s, 61.5%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.5% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Random:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Random: 100%|██████████| 128/128 [00:36<00:00,  3.55it/s, 93.0%]\n",
      "Current vs. Greedy: 100%|██████████| 128/128 [00:49<00:00,  2.59it/s, 72.7%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:21<00:00,  1.80it/s, 50.4%]\n",
      "Optimizing: 223it [00:34,  6.49it/s, 68.8%, 0.585L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:20<00:00,  1.82it/s, 39.8%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.8% Rejected new model\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:30<00:00,  1.70it/s, 43.4%]\n",
      "Optimizing: 227it [00:36,  6.18it/s, 64.5%, 0.607L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:22<00:00,  1.79it/s, 42.2%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2% Continuing to train current weights\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:19<00:00,  1.83it/s, 49.4%]\n",
      "Optimizing: 211it [00:33,  6.34it/s, 71.5%, 0.483L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:10<00:00,  1.97it/s, 42.2%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2% Continuing to train current weights\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:00<00:00,  2.12it/s, 48.4%]\n",
      "Optimizing: 174it [00:27,  6.29it/s, 65.4%, 0.584L]\n",
      "Current vs. Checkpoint:  40%|███▉      | 102/256 [00:51<01:11,  2.17it/s, 25.0%]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-76c3f34b1fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate against checkpoint model and other baselines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mopp_winrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPISODES_PER_ITERATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopp_winrate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mplay_games\u001b[0;34m(go_env, first_policy, second_policy, get_traj, episodes)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mwins\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mpit\u001b[0;34m(go_env, black_policy, white_policy, get_traj)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Get an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoVars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLACK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblack_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcurr_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoVars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHITE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/policies.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, state, step)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minvalid_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mbatch_qvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo_ai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontecarlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqval_from_stateval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mqvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_qvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/montecarlo/__init__.py\u001b[0m in \u001b[0;36mqval_from_stateval\u001b[0;34m(states, val_func)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mcanonical_next_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_canonical_children_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mcanonical_next_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonical_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/montecarlo/__init__.py\u001b[0m in \u001b[0;36mbatch_canonical_children_states\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalid_move_idcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_moves\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_move_idcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mnext_turn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcanonical_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_canonical_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/gogame.py\u001b[0m in \u001b[0;36mget_next_state\u001b[0;34m(state, action)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Update illegal moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mstate_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_invalid_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# This move was not a pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36madd_invalid_moves\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mour_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_adjacent_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Check whether we can kill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36mget_adjacent_groups\u001b[0;34m(state, location)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0madjacent_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_adjacent_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjacent_locations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mour_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mopponent_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36mget_group\u001b[0;34m(state, player, location)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mcalculate_group_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36mcalculate_group_helper\u001b[0;34m(group, turn, location, visited)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjacent_locations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mcalculate_group_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Part of liberty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36mcalculate_group_helper\u001b[0;34m(group, turn, location, visited)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjacent_locations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mcalculate_group_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Part of liberty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36mcalculate_group_helper\u001b[0;34m(group, turn, location, visited)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Part of liberty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliberties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Make and write out the episode data\n",
    "    _, replay_data = game.play_games(go_env, curr_policy, curr_policy, True, EPISODES_PER_ITERATION)\n",
    "        \n",
    "    # Process the data\n",
    "    random.shuffle(replay_data)\n",
    "    replay_data = data.replaylist_to_numpy(replay_data)\n",
    "\n",
    "    # Optimize\n",
    "    curr_model.optimize(replay_data, optim, BATCH_SIZE)\n",
    "    \n",
    "    # Evaluate against checkpoint model and other baselines\n",
    "    opp_winrate, _ = game.play_games(go_env, curr_policy, checkpoint_policy, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    if opp_winrate > 0.6:\n",
    "        # New parameters are significantly better. Accept it\n",
    "        torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "        checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Accepted new model\")\n",
    "        \n",
    "        # Plot samples of states and response heatmaps\n",
    "        metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)\n",
    "        print(\"Plotted sample trajectory\")\n",
    "        \n",
    "        rand_winrate, _ = game.play_games(go_env, curr_policy, random_policy, False, NUM_EVAL_GAMES)\n",
    "        greed_winrate, _ = game.play_games(go_env, curr_policy, greedy_policy, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    elif opp_winrate >= 0.4:\n",
    "        # Keep trying\n",
    "        print(f\"{100*opp_winrate:.1f}% Continuing to train current weights\")\n",
    "    else:\n",
    "        # New parameters are significantly worse. Reject it.\n",
    "        curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Rejected new model\")\n",
    "        \n",
    "    # Decay the temperatures if any\n",
    "    decay_temps([curr_policy, checkpoint_policy], TEMP_DECAY, MIN_TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moy9uJ6fGa7z"
   },
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_temps([curr_policy, checkpoint_policy], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA"
   },
   "outputs": [],
   "source": [
    "game.pit(go_env, human_policy, checkpoint_policy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emKESg3hGa71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of go_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
