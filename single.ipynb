{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from go_ai import policies, game, metrics, data\n",
    "from go_ai.models import value_model\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 256\n",
    "NUM_EVAL_GAMES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SEARCHES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TEMP = 1/64\n",
    "TEMP_DECAY = 3/4\n",
    "MIN_TEMP = 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8pWCj8jGa7Y"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES_DIR = 'episodes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfJcqNeEGa7b"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/checkpoint_{}x{}.pt'.format(BOARD_SIZE, BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_TRAJECTORY_PATH = 'logs/a_trajectory.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4m-C0k6Ga7q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueNet(\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(6, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_model = value_model.ValueNet(BOARD_SIZE)\n",
    "checkpoint_model = value_model.ValueNet(BOARD_SIZE)\n",
    "\n",
    "if LOAD_SAVED_MODELS:\n",
    "    assert os.path.exists(CHECKPOINT_PATH)\n",
    "    print(\"Starting from checkpoint\")\n",
    "else:\n",
    "    torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "    print(\"Initialized checkpoint\") \n",
    "\n",
    "curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "\n",
    "optim = torch.optim.Adam(curr_model.parameters(), 1e-3)\n",
    "curr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pi = policies.MctPolicy('Current', BOARD_SIZE, curr_model, INIT_TEMP, NUM_SEARCHES)\n",
    "checkpoint_pi = policies.MctPolicy('Checkpoint', BOARD_SIZE, checkpoint_model, INIT_TEMP, NUM_SEARCHES)\n",
    "\n",
    "rand_pi = policies.RandomPolicy()\n",
    "greedy_pi = policies.QTempPolicy('Greedy', policies.greedy_val_func, 0)\n",
    "greedymct_pi = policies.MctPolicy('MCT', BOARD_SIZE, policies.greedy_val_func, 0, NUM_SEARCHES)\n",
    "\n",
    "human_policy = policies.HumanPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_temps(policies, temp_decay, min_temp):\n",
    "    for policy in policies:\n",
    "        assert hasattr(policy, 'temp')\n",
    "        policy.temp *= temp_decay\n",
    "        if policy.temp < min_temp:\n",
    "            policy.temp = min_temp\n",
    "        print(f\"{policy.name} temp decayed to {policy.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVCEKWx_Ga7r"
   },
   "source": [
    "# Sample Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrTjrYjBGa7u"
   },
   "outputs": [],
   "source": [
    "metrics.plot_traj_fig(go_env, curr_pi, DEMO_TRAJECTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "outputId": "100dda95-316e-457c-b1f3-c8bf82243c52",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current:   1%|          | 3/256 [00:23<33:06,  7.85s/it, 66.7%]"
     ]
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Make and write out the episode data\n",
    "    _, replay_data = game.play_games(go_env, curr_pi, curr_pi, True, EPISODES_PER_ITERATION)\n",
    "        \n",
    "    # Process the data\n",
    "    random.shuffle(replay_data)\n",
    "    replay_data = data.replaylist_to_numpy(replay_data)\n",
    "\n",
    "    # Optimize\n",
    "    curr_model.optimize(replay_data, optim, BATCH_SIZE)\n",
    "    \n",
    "    # Evaluate against checkpoint model and other baselines\n",
    "    opp_winrate, _ = game.play_games(go_env, curr_pi, checkpoint_pi, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    if opp_winrate > 0.6:\n",
    "        # New parameters are significantly better. Accept it\n",
    "        torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "        checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Accepted new model\")\n",
    "        \n",
    "        # Plot samples of states and response heatmaps\n",
    "        metrics.plot_traj_fig(go_env, curr_pi, DEMO_TRAJECTORY_PATH)\n",
    "        print(\"Plotted sample trajectory\")\n",
    "        \n",
    "        rand_winrate, _ = game.play_games(go_env, curr_pi, rand_pi, False, NUM_EVAL_GAMES)\n",
    "        greed_winrate, _ = game.play_games(go_env, curr_pi, greedy_pi, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    elif opp_winrate >= 0.4:\n",
    "        # Keep trying\n",
    "        print(f\"{100*opp_winrate:.1f}% Continuing to train current weights\")\n",
    "    else:\n",
    "        # New parameters are significantly worse. Reject it.\n",
    "        curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Rejected new model\")\n",
    "        \n",
    "    # Decay the temperatures if any\n",
    "    decay_temps([curr_pi, checkpoint_pi], TEMP_DECAY, MIN_TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moy9uJ6fGa7z"
   },
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_temps([curr_pi, checkpoint_pi], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA"
   },
   "outputs": [],
   "source": [
    "game.pit(go_env, human_policy, checkpoint_pi, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emKESg3hGa71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of go_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
