{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from go_ai import policies, game, metrics, data\n",
    "from go_ai.models import value_model\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 256\n",
    "NUM_EVAL_GAMES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TEMP = 1/64\n",
    "TEMP_DECAY = 3/4\n",
    "MIN_TEMP = 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8pWCj8jGa7Y"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODELS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES_DIR = 'episodes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfJcqNeEGa7b"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/checkpoint_{}x{}.pt'.format(BOARD_SIZE, BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_TRAJECTORY_PATH = 'logs/a_trajectory.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4m-C0k6Ga7q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueNet(\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(6, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_model = value_model.ValueNet(BOARD_SIZE)\n",
    "checkpoint_model = value_model.ValueNet(BOARD_SIZE)\n",
    "\n",
    "if LOAD_SAVED_MODELS:\n",
    "    assert os.path.exists(CHECKPOINT_PATH)\n",
    "    print(\"Starting from checkpoint\")\n",
    "else:\n",
    "    torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "    print(\"Initialized checkpoint\") \n",
    "\n",
    "curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "\n",
    "optim = torch.optim.Adam(curr_model.parameters(), 1e-3)\n",
    "curr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_policy = policies.QTempPolicy('Current', curr_model, INIT_TEMP)\n",
    "checkpoint_policy = policies.QTempPolicy('Checkpoint', checkpoint_model, INIT_TEMP)\n",
    "\n",
    "random_policy = policies.RandomPolicy()\n",
    "greedy_policy = policies.QTempPolicy('Greedy', policies.greedy_val_func, temp=0)\n",
    "human_policy = policies.HumanPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_temps(policies, temp_decay, min_temp):\n",
    "    for policy in policies:\n",
    "        assert hasattr(policy, 'temp')\n",
    "        policy.temp *= temp_decay\n",
    "        if policy.temp < min_temp:\n",
    "            policy.temp = min_temp\n",
    "        print(f\"{policy.name} temp decayed to {policy.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVCEKWx_Ga7r"
   },
   "source": [
    "# Demo and Time Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSQ1RFHuGa7r"
   },
   "source": [
    "Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 372 ms, sys: 39.7 ms, total: 412 ms\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "action = (1, 1)\n",
    "next_state, _, _, _ = go_env.step(action)\n",
    "metrics.plot_symmetries(next_state, 'logs/symmetries.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 664 ms, sys: 66.2 ms, total: 730 ms\n",
      "Wall time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "_,_ = game.pit(go_env, curr_policy, curr_policy, get_traj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrTjrYjBGa7u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.65 s, sys: 121 ms, total: 3.77 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "outputId": "100dda95-316e-457c-b1f3-c8bf82243c52",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:02<00:00,  2.08it/s, 54.5%]\n",
      "Optimizing: 178it [00:27,  6.39it/s, 57.8%, 0.663L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:11<00:00,  1.95it/s, 61.3%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.3% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.75\n",
      "Checkpoint temp decayed to 0.75\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:08<00:00,  1.99it/s, 55.3%]\n",
      "Optimizing: 183it [00:29,  6.19it/s, 62.3%, 0.655L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:04<00:00,  2.05it/s, 50.4%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.4% Continuing to train current weights\n",
      "Current temp decayed to 0.5625\n",
      "Checkpoint temp decayed to 0.5625\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:48<00:00,  1.52it/s, 55.5%]\n",
      "Optimizing: 168it [01:51,  1.51it/s, 65.5%, 0.637L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [10:22<00:00,  2.43s/it, 52.5%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.5% Continuing to train current weights\n",
      "Current temp decayed to 0.421875\n",
      "Checkpoint temp decayed to 0.421875\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [10:57<00:00,  2.57s/it, 55.9%]\n",
      "Optimizing: 193it [02:05,  1.54it/s, 63.9%, 0.643L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [07:14<00:00,  1.70s/it, 52.0%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0% Continuing to train current weights\n",
      "Current temp decayed to 0.31640625\n",
      "Checkpoint temp decayed to 0.31640625\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [42:52<00:00, 10.05s/it, 56.4%]   \n",
      "Optimizing: 170it [03:13,  1.14s/it, 64.5%, 0.633L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [41:28<00:00,  9.72s/it, 52.0%]   \n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0% Continuing to train current weights\n",
      "Current temp decayed to 0.2373046875\n",
      "Checkpoint temp decayed to 0.2373046875\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [08:28<00:00,  1.99s/it, 54.3%]\n",
      "Optimizing: 178it [02:18,  1.29it/s, 65.6%, 0.615L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [50:26<00:00, 11.82s/it, 55.3%]    \n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.3% Continuing to train current weights\n",
      "Current temp decayed to 0.177978515625\n",
      "Checkpoint temp decayed to 0.177978515625\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [29:52<00:00,  7.00s/it, 51.0%]   \n",
      "Optimizing: 169it [02:12,  1.27it/s, 63.5%, 0.619L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [10:42<00:00,  2.51s/it, 65.8%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.8% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.13348388671875\n",
      "Checkpoint temp decayed to 0.13348388671875\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [08:35<00:00,  2.01s/it, 58.6%]\n",
      "Optimizing: 194it [07:41,  2.38s/it, 67.1%, 0.617L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [10:53<00:00,  2.55s/it, 49.8%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.8% Continuing to train current weights\n",
      "Current temp decayed to 0.1001129150390625\n",
      "Checkpoint temp decayed to 0.1001129150390625\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [14:12<00:00,  3.33s/it, 58.6%]   \n",
      "Optimizing: 162it [02:34,  1.05it/s, 75.3%, 0.508L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [14:23<00:00,  3.37s/it, 61.5%]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.5% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.07508468627929688\n",
      "Checkpoint temp decayed to 0.07508468627929688\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [13:41<00:00,  3.21s/it, 57.6%] \n",
      "Optimizing: 190it [02:40,  1.19it/s, 71.9%, 0.528L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [15:04<00:00,  3.53s/it, 54.5%]  \n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.5% Continuing to train current weights\n",
      "Current temp decayed to 0.056313514709472656\n",
      "Checkpoint temp decayed to 0.056313514709472656\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [12:21<00:00,  2.90s/it, 51.8%] \n",
      "Optimizing: 212it [03:35,  1.01s/it, 69.4%, 0.583L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [15:54<00:00,  3.73s/it, 44.7%]  \n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.7% Continuing to train current weights\n",
      "Current temp decayed to 0.04223513603210449\n",
      "Checkpoint temp decayed to 0.04223513603210449\n",
      "Iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [16:09<00:00,  3.79s/it, 61.3%]   \n",
      "Optimizing: 128it [07:44,  3.63s/it, 71.9%, 0.518L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [14:01<00:00,  3.29s/it, 54.9%]\n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.9% Continuing to train current weights\n",
      "Current temp decayed to 0.03167635202407837\n",
      "Checkpoint temp decayed to 0.03167635202407837\n",
      "Iteration 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [14:06<00:00,  3.31s/it, 59.6%]  \n",
      "Optimizing: 225it [03:43,  1.01it/s, 60.0%, 0.683L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [11:39<00:00,  2.73s/it, 14.5%] \n",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5% Rejected new model\n",
      "Current temp decayed to 0.023757264018058777\n",
      "Checkpoint temp decayed to 0.023757264018058777\n",
      "Iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [12:54<00:00,  3.03s/it, 67.6%] \n",
      "Optimizing: 195it [09:29,  2.92s/it, 80.0%, 0.427L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [16:49<00:00,  3.94s/it, 84.6%]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.6% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.017817948013544083\n",
      "Checkpoint temp decayed to 0.017817948013544083\n",
      "Iteration 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [1:36:21<00:00, 22.58s/it, 91.2%]   \n",
      "Optimizing: 156it [00:33,  4.70it/s, 91.4%, 0.259L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:19<00:00,  1.83it/s, 63.9%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.9% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:17<00:00,  1.86it/s, 72.7%]\n",
      "Optimizing: 203it [00:40,  5.04it/s, 72.9%, 0.592L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [01:48<00:00,  2.36it/s, 79.7%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.7% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [01:50<00:00,  2.32it/s, 88.1%]\n",
      "Optimizing: 139it [00:29,  4.77it/s, 88.3%, 0.324L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [01:52<00:00,  2.27it/s, 95.1%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.1% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:12<00:00,  1.93it/s, 76.0%]\n",
      "Optimizing: 204it [00:40,  5.01it/s, 81.6%, 0.405L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:08<00:00,  2.00it/s, 79.5%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.5% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [13:00<00:00,  3.05s/it, 76.0%]  \n",
      "Optimizing: 185it [00:36,  5.03it/s, 84.4%, 0.370L]\n",
      "Current vs. Checkpoint: 100%|██████████| 256/256 [02:07<00:00,  2.01it/s, 85.9%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.9% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n",
      "Current temp decayed to 0.015625\n",
      "Checkpoint temp decayed to 0.015625\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 256/256 [02:04<00:00,  2.06it/s, 78.9%]\n",
      "Optimizing: 180it [00:38,  4.71it/s, 80.3%, 0.408L]\n",
      "Current vs. Checkpoint:  42%|████▏     | 108/256 [01:02<01:19,  1.87it/s, 37.0%]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7707ee5c7318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate against checkpoint model and other baselines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mopp_winrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPISODES_PER_ITERATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopp_winrate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mplay_games\u001b[0;34m(go_env, black_policy, white_policy, get_traj, episodes)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgo_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mpit\u001b[0;34m(go_env, black_policy, white_policy, get_traj)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Get an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoVars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLACK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblack_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/policies.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, state, step)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minvalid_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mbatch_qvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo_ai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontecarlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqval_from_stateval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mqvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_qvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/montecarlo/__init__.py\u001b[0m in \u001b[0;36mqval_from_stateval\u001b[0;34m(states, val_func)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcanonical_next_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_canonical_children_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mcanonical_next_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonical_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcurr_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/policies.py\u001b[0m in \u001b[0;36mval_func\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mstate_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mstate_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/models/value_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Make and write out the episode data\n",
    "    _, replay_data = game.play_games(go_env, curr_policy, curr_policy, True, EPISODES_PER_ITERATION)\n",
    "        \n",
    "    # Process the data\n",
    "    random.shuffle(replay_data)\n",
    "    replay_data = data.replaylist_to_numpy(replay_data)\n",
    "\n",
    "    # Optimize\n",
    "    curr_model.optimize(replay_data, optim, BATCH_SIZE)\n",
    "    \n",
    "    # Evaluate against checkpoint model and other baselines\n",
    "    opp_winrate, _ = game.play_games(go_env, curr_policy, checkpoint_policy, False, EPISODES_PER_ITERATION)\n",
    "\n",
    "    if opp_winrate > 0.6:\n",
    "        # New parameters are significantly better. Accept it\n",
    "        torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "        checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Accepted new model\")\n",
    "        \n",
    "        # Plot samples of states and response heatmaps\n",
    "        metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)\n",
    "        print(\"Plotted sample trajectory\")\n",
    "        \n",
    "        rand_winrate, _ = game.play_games(go_env, curr_policy, random_policy, False, NUM_EVAL_GAMES)\n",
    "        greed_winrate, _ = game.play_games(go_env, curr_policy, greedy_policy, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    elif opp_winrate >= 0.4:\n",
    "        # Keep trying\n",
    "        print(f\"{100*opp_winrate:.1f}% Continuing to train current weights\")\n",
    "    else:\n",
    "        # New parameters are significantly worse. Reject it.\n",
    "        curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Rejected new model\")\n",
    "        \n",
    "    # Decay the temperatures if any\n",
    "    decay_temps([curr_policy, checkpoint_policy], TEMP_DECAY, MIN_TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moy9uJ6fGa7z"
   },
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_temps([curr_policy, checkpoint_policy], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA"
   },
   "outputs": [],
   "source": [
    "game.pit(go_env, human_policy, checkpoint_policy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emKESg3hGa71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of go_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
