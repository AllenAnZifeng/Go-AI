{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from go_ai import policies, game, metrics, data\n",
    "from go_ai.models import value_model\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 128\n",
    "NUM_EVAL_GAMES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TEMP = 1\n",
    "TEMP_DECAY = 3/4\n",
    "MIN_TEMP = 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8pWCj8jGa7Y"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES_DIR = 'episodes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfJcqNeEGa7b"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/checkpoint_{}x{}.pt'.format(BOARD_SIZE, BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_TRAJECTORY_PATH = 'logs/a_trajectory.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4m-C0k6Ga7q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueNet(\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_model = value_model.ValueNet(BOARD_SIZE)\n",
    "checkpoint_model = value_model.ValueNet(BOARD_SIZE)\n",
    "\n",
    "if LOAD_SAVED_MODELS:\n",
    "    assert os.path.exists(CHECKPOINT_PATH)\n",
    "    print(\"Starting from checkpoint\")\n",
    "else:\n",
    "    torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "    print(\"Initialized checkpoint\") \n",
    "\n",
    "curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "\n",
    "curr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_policy = policies.QTempPolicy('Current', curr_model, INIT_TEMP)\n",
    "checkpoint_policy = policies.QTempPolicy('Checkpoint', checkpoint_model, INIT_TEMP)\n",
    "\n",
    "random_policy = policies.RandomPolicy()\n",
    "greedy_policy = policies.QTempPolicy('Greedy', policies.greedy_val_func, temp=0)\n",
    "human_policy = policies.HumanPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_temps(policies, temp_decay, min_temp):\n",
    "    for policy in policies:\n",
    "        assert hasattr(policy, 'temp')\n",
    "        policy.temp *= temp_decay\n",
    "        if policy.temp < min_temp:\n",
    "            policy.temp = min_temp\n",
    "        print(f\"{policy.name} temp decayed to {policy.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVCEKWx_Ga7r"
   },
   "source": [
    "# Demo and Time Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSQ1RFHuGa7r"
   },
   "source": [
    "Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 32.6 ms, total: 371 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "action = (1, 1)\n",
    "next_state, _, _, _ = go_env.step(action)\n",
    "metrics.plot_symmetries(next_state, 'logs/symmetries.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 504 ms, sys: 63.3 ms, total: 567 ms\n",
      "Wall time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "_,_ = game.pit(go_env, curr_policy, curr_policy, get_traj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrTjrYjBGa7u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 99.4 ms, total: 2.36 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "outputId": "100dda95-316e-457c-b1f3-c8bf82243c52",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Current vs. Current:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 128/128 [00:25<00:00,  5.04it/s, 59.0%]\n",
      "Optimizing: 82it [00:00, 175.68it/s, 52.4%, 0.692L]\n",
      "Current vs. Checkpoint: 100%|██████████| 128/128 [00:24<00:00,  5.17it/s, 60.2%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.2% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Random:   2%|▏         | 2/128 [00:00<00:11, 10.74it/s, 100.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted sample trajectory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Random: 100%|██████████| 128/128 [00:15<00:00,  8.39it/s, 52.0%]\n",
      "Current vs. Greedy: 100%|██████████| 128/128 [00:26<00:00,  4.85it/s, 4.7%]\n",
      "Current vs. Current:   1%|          | 1/128 [00:00<00:21,  5.88it/s, 100.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current temp decayed to 0.75\n",
      "Checkpoint temp decayed to 0.75\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 128/128 [00:27<00:00,  4.62it/s, 52.3%]\n",
      "Optimizing: 91it [00:00, 182.48it/s, 52.4%, 0.693L]\n",
      "Current vs. Checkpoint: 100%|██████████| 128/128 [00:26<00:00,  4.92it/s, 57.0%]\n",
      "Current vs. Current:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.0% Continuing to train current weights\n",
      "Current temp decayed to 0.5625\n",
      "Checkpoint temp decayed to 0.5625\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 128/128 [00:25<00:00,  5.02it/s, 55.9%]\n",
      "Optimizing: 81it [00:00, 168.01it/s, 52.5%, 0.693L]\n",
      "Current vs. Checkpoint: 100%|██████████| 128/128 [00:24<00:00,  5.31it/s, 57.4%]\n",
      "Current vs. Current:   1%|          | 1/128 [00:00<00:22,  5.57it/s, 0.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.4% Continuing to train current weights\n",
      "Current temp decayed to 0.421875\n",
      "Checkpoint temp decayed to 0.421875\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 128/128 [00:23<00:00,  5.37it/s, 60.5%]\n",
      "Optimizing: 80it [00:00, 184.48it/s, 51.7%, 0.693L]\n",
      "Current vs. Checkpoint: 100%|██████████| 128/128 [00:24<00:00,  5.30it/s, 58.6%]\n",
      "Current vs. Current:   0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.6% Continuing to train current weights\n",
      "Current temp decayed to 0.31640625\n",
      "Checkpoint temp decayed to 0.31640625\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current vs. Current: 100%|██████████| 128/128 [00:23<00:00,  5.49it/s, 64.1%]\n",
      "Optimizing: 76it [00:00, 181.74it/s, 49.3%, 0.694L]\n",
      "Current vs. Checkpoint:  15%|█▍        | 19/128 [00:03<00:21,  4.99it/s, 47.4%]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c599919f3e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate against checkpoint model and other baselines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mopp_winrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPISODES_PER_ITERATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopp_winrate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mplay_games\u001b[0;34m(go_env, policy1, policy2, get_traj, episodes)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgo_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwins\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/game.py\u001b[0m in \u001b[0;36mpit\u001b[0;34m(go_env, black_policy, white_policy, get_traj)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcurr_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoVars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHITE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhite_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_weighted_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/policies.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, state, step)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minvalid_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mbatch_qvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo_ai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontecarlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqval_from_stateval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mqvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_qvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/montecarlo/__init__.py\u001b[0m in \u001b[0;36mqval_from_stateval\u001b[0;34m(states, val_func)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mcanonical_next_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_canonical_children_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mcanonical_next_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonical_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/montecarlo/__init__.py\u001b[0m in \u001b[0;36mbatch_canonical_children_states\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalid_move_idcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_moves\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_move_idcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mnext_turn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcanonical_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoGame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_canonical_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/gogame.py\u001b[0m in \u001b[0;36mget_next_state\u001b[0;34m(state, action)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Update invalid channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mstate_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_invalid_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mstate_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_invalid_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Switch turn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/GymGo/gym_go/state_utils.py\u001b[0m in \u001b[0;36madd_invalid_moves\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINVD_CHNL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Occupied/ko invalidness already taken care of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Make and write out the episode data\n",
    "    _, replay_data = game.play_games(go_env, curr_policy, curr_policy, True, EPISODES_PER_ITERATION)\n",
    "        \n",
    "    # Process the data\n",
    "    random.shuffle(replay_data)\n",
    "    replay_data = data.replaylist_to_numpy(replay_data)\n",
    "\n",
    "    # Optimize\n",
    "    curr_model.optimize(replay_data, BATCH_SIZE)\n",
    "    \n",
    "    # Evaluate against checkpoint model and other baselines\n",
    "    opp_winrate, _ = game.play_games(go_env, curr_policy, checkpoint_policy, False, EPISODES_PER_ITERATION)\n",
    "\n",
    "    if opp_winrate > 0.6:\n",
    "        # New parameters are significantly better. Accept it\n",
    "        torch.save(curr_model.state_dict(), CHECKPOINT_PATH)\n",
    "        checkpoint_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Accepted new model\")\n",
    "        \n",
    "        # Plot samples of states and response heatmaps\n",
    "        metrics.gen_traj_fig(go_env, curr_policy, DEMO_TRAJECTORY_PATH)\n",
    "        print(\"Plotted sample trajectory\")\n",
    "        \n",
    "        rand_winrate, _ = game.play_games(go_env, curr_policy, random_policy, False, NUM_EVAL_GAMES)\n",
    "        greed_winrate, _ = game.play_games(go_env, curr_policy, greedy_policy, False, NUM_EVAL_GAMES)\n",
    "\n",
    "    elif opp_winrate >= 0.4:\n",
    "        # Keep trying\n",
    "        print(f\"{100*opp_winrate:.1f}% Continuing to train current weights\")\n",
    "    else:\n",
    "        # New parameters are significantly worse. Reject it.\n",
    "        curr_model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print(f\"{100*opp_winrate:.1f}% Rejected new model\")\n",
    "        \n",
    "    # Decay the temperatures if any\n",
    "    decay_temps([curr_policy, checkpoint_policy], TEMP_DECAY, MIN_TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moy9uJ6fGa7z"
   },
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_temps([curr_policy, checkpoint_policy], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA"
   },
   "outputs": [],
   "source": [
    "game.pit(go_env, human_policy, checkpoint_policy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emKESg3hGa71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of go_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
