{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "colab_type": "code",
    "id": "5YQ7bYMnwJRa",
    "outputId": "65617db9-e466-4ec7-d8e9-d829a89dc2a1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install tensorflow==2.0.0-beta1\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "# Restart the jupyter notebook if you just installed TF 2.0 Beta\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc1lqGjPwJRm"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board with heuristic reward for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -e gym-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S', reward_method='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7ZoRfzIwJRr"
   },
   "source": [
    "# Machine Learning Models\n",
    "Deep Q Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9wWb0HvwJRs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dqn():\n",
    "    inputs = layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 4), name=\"board\")\n",
    "    valid_inputs = layers.Input(shape=(BOARD_SIZE**2 + 1,), name=\"valid_moves\")\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=512, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    moves = layers.Dense(50)(x)\n",
    "    \n",
    "#     # Dense block\n",
    "#     num_layers = 8\n",
    "#     growth_rate = 4\n",
    "#     x = inputs\n",
    "#     for i in range(num_layers):\n",
    "#         y = tf.keras.Sequential([\n",
    "#             layers.Conv2D(filters=growth_rate, kernel_size=3, padding=\"same\", bias_initializer='ones'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.ReLU(),\n",
    "#         ], name='dense_layer_{}'.format(i))(x)\n",
    "#         x = layers.Concatenate()([x,y])\n",
    "    \n",
    "#     moves = layers.Conv2D(filters=50, kernel_size=BOARD_SIZE, padding=\"valid\", name=\"all_moves\")(x)\n",
    "    \n",
    "#     moves = layers.Flatten()(moves)\n",
    "    \n",
    "    valid_moves = layers.Multiply(name='moves')([moves, valid_inputs])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs, valid_inputs], outputs=valid_moves, name='DQN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dqn = make_dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 7, 7, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 16)     592         board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 16)     64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 7, 7, 16)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     9280        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 256)    147712      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 256)    1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 7, 7, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 256)    590080      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 256)    1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 7, 7, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 64)     147520      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 16)     9232        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 16)     64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 7, 7, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 64)     9280        re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          401536      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           6450        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "moves (Multiply)                (None, 50)           0           dense_1[0][0]                    \n",
      "                                                                 valid_moves[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,325,138\n",
      "Trainable params: 1,323,410\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dqn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = tf.keras.models.clone_model(dqn)\n",
    "target_policy = tf.keras.models.clone_model(dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9djBWO1wJR1"
   },
   "source": [
    "### Initialization of models \n",
    "should be random if the models are fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(states, model):\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    valid_moves = 1 - invalid_moves\n",
    "    moves = model([states.astype(np.float32), valid_moves.astype(np.float32)])\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_values(states):\n",
    "    \"\"\"\n",
    "    Returns the action values of the states where invalid moves have -infinity value (minimum value of float32)\n",
    "    and valid moves have 0 value\n",
    "    \"\"\"\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    invalid_values = (-np.finfo(np.float32).min) * invalid_moves\n",
    "    return invalid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_action_vals(states, actval_func):\n",
    "    '''\n",
    "    The maximum action value (including passing) given the states\n",
    "    '''\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, actval_func)\n",
    "    max_vals = tf.reduce_max(move_vals + invalid_values, axis=1)\n",
    "    return max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_action_vals(states, actval_func):\n",
    "    \"\"\"\n",
    "    Returns the moves that have the maximum values (including passing) given the states\n",
    "    \"\"\"\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, actval_func)\n",
    "    argmax_vals = tf.reduce_argmax(move_vals + invalid_values, axis=1)\n",
    "    \n",
    "    # Get the action\n",
    "    if argmax_vals == BOARD_SIZE**2:\n",
    "        action = None\n",
    "    else:\n",
    "        action = (argmax_vals // BOARD_SIZE, argmax_vals % BOARD_SIZE)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH4rDyuowJR3",
    "outputId": "6376f7a8-99ff-4352-e6fc-0eccd05dfa25",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def state_responses(states, taken_actions=None, next_states=None, rewards=None, terminals=None):\n",
    "    \"\"\"\n",
    "    Returns a figure of plots on the states and the models responses on those states\n",
    "    \"\"\"\n",
    "    state_values = max_action_vals(states, dqn)\n",
    "    move_values = feed_forward(states, dqn)\n",
    "    \n",
    "    if next_states is not None:\n",
    "        next_move_values = feed_forward(next_states, dqn)\n",
    "        next_state_values = max_action_vals(next_states, dqn)\n",
    "    else:\n",
    "        next_move_values = None\n",
    "        next_state_values = None\n",
    "        \n",
    "    num_states = states.shape[0]\n",
    "    num_cols = 2 if next_states is None else 4\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_cols * 3, num_states * 3))\n",
    "    for i in range(num_states):\n",
    "        plt.subplot(num_states,num_cols,1 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('Board')\n",
    "        plt.imshow(states[i][:,:,[0,1,3]].astype(np.float))\n",
    "\n",
    "        plt.subplot(num_states,num_cols,2 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                  .format(state_values[i], np.min(move_values[i][:-1]), \n",
    "                          np.max(move_values[i][:-1]), move_values[i][-1]))\n",
    "        plt.imshow(tf.reshape(move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "        \n",
    "        if next_states is not None:\n",
    "            assert taken_actions is not None and len(taken_actions) == len(next_states)\n",
    "            if i < next_states.shape[0]:\n",
    "                plt.subplot(num_states,num_cols, 3 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('Taken Action: {}\\n{}R {}T'.format(taken_actions[i], rewards[i], terminals[i]))\n",
    "                plt.imshow(next_states[i][:,:,[0,1,3]].astype(np.float))\n",
    "                \n",
    "                plt.subplot(num_states,num_cols,4 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                          .format(next_state_values[i], np.min(next_move_values[i][:-1]), \n",
    "                                  np.max(next_move_values[i][:-1]), next_move_values[i][-1]))\n",
    "                plt.imshow(tf.reshape(next_move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [],
   "source": [
    "state = go_env.reset()\n",
    "start_state = np.copy(state)\n",
    "state, reward, done, info = go_env.step((3,5))\n",
    "state, reward, done, info = go_env.step((5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJWxThQMwJRz"
   },
   "outputs": [],
   "source": [
    "states = state.transpose(1,2,0).reshape(1, BOARD_SIZE, BOARD_SIZE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(state_responses(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViUxxPnUwJR5"
   },
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 2000\n",
    "BATCH_SIZE = 256\n",
    "MAX_STEPS = 3 * BOARD_SIZE**2\n",
    "REPLAY_MEM_SIZE = 2e4\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "OPPONENT_UPDATE = 200\n",
    "\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 0.995\n",
    "EPSILON_MIN = 0.1\n",
    "\n",
    "GAMMA = 0.90\n",
    "TARGET_UPDATE = 1 # number of episodes to update the target critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([GAMMA**x for x in range(100)])\n",
    "plt.title(\"Gamma Powers\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sumB3IsFwJR6"
   },
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeB26mZvwJR7"
   },
   "outputs": [],
   "source": [
    "replay_mem = deque(maxlen=int(REPLAY_MEM_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for metric_key in ['loss', 'win_percentage']:\n",
    "    metrics[metric_key] = tf.keras.metrics.Mean('dqn_{}'.format(metric_key), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writers = {}\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "for summary_key in ['train', 'test']:\n",
    "    log_dir = 'logs/dqn/{}/{}'.format(current_time, summary_key)\n",
    "    summary_writers[summary_key] = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXOIVFjmwJR7"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weighted_action(move_weights):\n",
    "    move_weights = preprocessing.normalize(move_weights, norm='l1')\n",
    "\n",
    "    if np.sum(move_weights) <= 0:\n",
    "        # Pass\n",
    "        return None\n",
    "    \n",
    "    action_1d = np.random.choice(np.arange(BOARD_SIZE**2 + 1), p=move_weights[0])\n",
    "    if action_1d == BOARD_SIZE**2:\n",
    "        action = None\n",
    "    else:\n",
    "        action = (action_1d // BOARD_SIZE, action_1d % BOARD_SIZE)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(state):\n",
    "    \"\"\"\n",
    "    Assumed to be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    \"\"\"\n",
    "    invalid_moves = state[:,:,2].reshape((1,-1))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    move_weights = 1 - invalid_moves\n",
    "\n",
    "    action = random_weighted_action(move_weights)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(policy, state, epsilon):\n",
    "    \"\"\"\n",
    "    Gets an action based on exploration/exploitation\n",
    "    \"\"\"\n",
    "    if state.shape[0] == 4:\n",
    "        # State shape will be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "        state = state.transpose(1,2,0)\n",
    "            \n",
    "    epsilon_choice = np.random.uniform()\n",
    "    if epsilon_choice < epsilon:\n",
    "        # Random move\n",
    "        logging.debug(\"Exploring a random move\")\n",
    "        action = random_action(state)\n",
    "        \n",
    "    else:\n",
    "        # policy makes a move\n",
    "        logging.debug(\"Exploiting policy's move\")\n",
    "        reshaped_state = state.reshape(1, BOARD_SIZE, BOARD_SIZE, 4).astype(np.float32)\n",
    "        \n",
    "        action = argmax_action_vals(reshaped_state, policy):\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_for_action(move_values, actions):\n",
    "    '''\n",
    "    Get value from board_values based on action, or take the passing_values if the action is None\n",
    "    '''\n",
    "    action_values = tf.gather_nd(move_values, [(i, a[0] * BOARD_SIZE + a[1]) if a is not None \n",
    "                                                    else (i, BOARD_SIZE**2) \n",
    "                                                    for i, a in enumerate(actions)])\n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_obs(size=BATCH_SIZE):\n",
    "    '''\n",
    "    Get a batch of orig_states, actions, states, rewards, terminals as np array out of replay memory\n",
    "    '''\n",
    "    \n",
    "    # States were (BATCH_SIZE, 4, BOARD_SIZE, BOARD_SIZE)\n",
    "    # Convert them to (BATCH_SIZE, BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    batch = random.sample(replay_mem, size)\n",
    "    batch = list(zip(*batch))\n",
    "    orig_states = np.array(list(batch[0]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    actions = np.array(list(batch[1]))\n",
    "    states = np.array(list(batch[2]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    rewards = np.array(list(batch[3]), dtype=np.float32)\n",
    "    terminals = np.array(list(batch[4]), dtype=np.uint8)\n",
    "    \n",
    "    return orig_states, actions, states, rewards, terminals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_heatmaps():\n",
    "    num_samples = 3\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs(num_samples)\n",
    "    states = np.concatenate([states, start_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "    fig = state_responses(states, actions, next_states, rewards, terminals)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error = tf.keras.losses.MeanSquaredError(reduction=tf.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8QseVrawJR8"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "def update_dqn():\n",
    "    \"\"\"\n",
    "    Optimizes the critic in one step and updates the critic loss metric\n",
    "    \"\"\"\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs()\n",
    "    \n",
    "    # get values for next state\n",
    "    next_state_vals = max_action_vals(next_states, target_policy)\n",
    "    \n",
    "    batch_size = states.shape[0]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        move_vals = feed_forward(states, dqn)\n",
    "        action_vals = get_value_for_action(move_vals, actions)\n",
    "        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
    "    \n",
    "    metrics['loss'](val_loss)\n",
    "    \n",
    "    # compute and apply gradients\n",
    "    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0E04emPwJR-"
   },
   "outputs": [],
   "source": [
    "def play_a_game(episode, train, opponent_epsilon=0):\n",
    "    \"\"\"\n",
    "    Plays out a game, and iteratively updates the models at each step\n",
    "    Returns the number of moves by the end of the game and the list \n",
    "    of rewards after every turn by the black player\n",
    "    \"\"\"\n",
    "    global EPSILON\n",
    "    \n",
    "    # Basic setup\n",
    "    done = False\n",
    "    num_of_turns = 0\n",
    "    state = go_env.reset()\n",
    "    rewards = []\n",
    "    \n",
    "    while not done and num_of_turns <= MAX_STEPS:\n",
    "        # Copy state for memory\n",
    "        orig_state = np.copy(state)\n",
    "        \n",
    "        black_action = get_action(dqn, state, EPSILON)\n",
    "        if black_action is None:\n",
    "            logging.debug(\"Black (actor) passed\")\n",
    "            \n",
    "        state, reward, done, info = go_env.step(black_action)\n",
    "        num_of_turns += 1\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Update the critic and then actor if we are training and have enough events\n",
    "        if train and len(replay_mem) >= BATCH_SIZE:\n",
    "            update_dqn()        \n",
    "    \n",
    "            # Update exploration/exploitation\n",
    "            if EPSILON > EPSILON_MIN:\n",
    "                EPSILON *= EPSILON_DECAY\n",
    "                logging.debug(\"Epsilon decayed to {}\".format(EPSILON))\n",
    "            \n",
    "        if done:\n",
    "            # Add to memory\n",
    "            replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "            break\n",
    "            \n",
    "        # opponent makes a move\n",
    "        # swap the black and white layers\n",
    "        temp = np.copy(state[0])\n",
    "        state[0] = state[1]\n",
    "        state[1] = temp\n",
    "        # get action from opponent\n",
    "        white_action = get_action(None, state, epsilon=opponent_epsilon)\n",
    "        if white_action is None:\n",
    "            logging.debug(\"White (opponent) passed\")\n",
    "\n",
    "        state, reward, done, info = go_env.step(white_action)\n",
    "        \n",
    "        # Add to memory\n",
    "        replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "        \n",
    "        num_of_turns += 1\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    # Game ended\n",
    "    return num_of_turns, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT1PUXyXwJR_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [1:31:41<849:17:55, 1544.96s/it]"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(NUM_EPISODES)):\n",
    "    # Reset all metrics\n",
    "    for metric in metrics.values():\n",
    "        metric.reset_states()\n",
    "        \n",
    "    # Update other models if appropriate\n",
    "    dqn.save_weights('tmp/dqn.h5')\n",
    "    if episode % OPPONENT_UPDATE == 0:\n",
    "        opponent.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated opponent\")\n",
    "        \n",
    "    if episode % TARGET_UPDATE == 0:\n",
    "        target_policy.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated policy\")\n",
    "        \n",
    "    # Train\n",
    "    num_turns, rewards = play_a_game(episode, train=True, opponent_epsilon=1)\n",
    "    \n",
    "    # Plot samples of states and response heatmaps\n",
    "    fig = sample_heatmaps()\n",
    "    \n",
    "    # log results\n",
    "    with summary_writers['train'].as_default():\n",
    "        tf.summary.image(\"model heat maps\", plot_to_image(fig), step=episode)\n",
    "        \n",
    "        tf.summary.scalar('last rewards', rewards[-1], step=episode)\n",
    "        tf.summary.scalar('number of moves', num_turns, step=episode)\n",
    "        tf.summary.scalar('loss', metrics['loss'].result(), step=episode)\n",
    "        tf.summary.scalar('epsilon', EPSILON, step=episode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get win percentage from 100 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'play_a_game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95bdec94319a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnum_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_a_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'play_a_game' is not defined"
     ]
    }
   ],
   "source": [
    "wins = []\n",
    "for _ in range(100):\n",
    "    num_moves, rewards = play_a_game(episode=None, train=False, opponent_epsilon=1)\n",
    "    win = rewards[-1]\n",
    "    wins.append(win)\n",
    "print(np.average(wins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test against a pretrained AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA",
    "outputId": "4d6aa1e6-8b63-4a39-b600-e331284ad6ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S')\n",
    "\n",
    "state = go_env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    go_env.render()\n",
    "    \n",
    "    # Actor's move\n",
    "    action = get_action(dqn, state, epsilon=0)\n",
    "    \n",
    "    state, reward, done, info = go_env.step(action)\n",
    "    \n",
    "    go_env.render()\n",
    "    \n",
    "    # Player's move\n",
    "    player_moved = False\n",
    "    while not player_moved:\n",
    "        coords = input(\"Enter coordinates separated by space (`q` to quit)\\n\")\n",
    "        if coords == 'q':\n",
    "            done = True\n",
    "            break\n",
    "        coords = coords.split()\n",
    "        try:\n",
    "            row = int(coords[0])\n",
    "            col = int(coords[1])\n",
    "            print(row, col)\n",
    "            state, reward, done, info = go_env.step((row, col))\n",
    "            player_moved = True\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "go_ai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
