{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "colab_type": "code",
    "id": "5YQ7bYMnwJRa",
    "outputId": "65617db9-e466-4ec7-d8e9-d829a89dc2a1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install tensorflow==2.0.0-beta1\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "# Restart the jupyter notebook if you just installed TF 2.0 Beta\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc1lqGjPwJRm"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board with heuristic reward for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -e gym-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S', reward_method='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7ZoRfzIwJRr"
   },
   "source": [
    "# Machine Learning Models\n",
    "Deep Q Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9wWb0HvwJRs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dqn():\n",
    "    inputs = layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 4), name=\"board\")\n",
    "    valid_inputs = layers.Input(shape=(BOARD_SIZE**2 + 1,), name=\"valid_moves\")\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=1, kernel_size=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    moves = layers.Dense(50)(x)\n",
    "    \n",
    "#     # Dense block\n",
    "#     num_layers = 8\n",
    "#     growth_rate = 4\n",
    "#     x = inputs\n",
    "#     for i in range(num_layers):\n",
    "#         y = tf.keras.Sequential([\n",
    "#             layers.Conv2D(filters=growth_rate, kernel_size=3, padding=\"same\", bias_initializer='ones'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.ReLU(),\n",
    "#         ], name='dense_layer_{}'.format(i))(x)\n",
    "#         x = layers.Concatenate()([x,y])\n",
    "    \n",
    "#     moves = layers.Conv2D(filters=50, kernel_size=BOARD_SIZE, padding=\"valid\", name=\"all_moves\")(x)\n",
    "    \n",
    "#     moves = layers.Flatten()(moves)\n",
    "    \n",
    "    valid_moves = layers.Multiply(name='moves')([moves, valid_inputs])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs, valid_inputs], outputs=valid_moves, name='DQN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dqn = make_dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 7, 7, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 64)     2368        board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 64)     256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 7, 7, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     36928       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1)      65          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1)      4           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 7, 7, 1)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 49)           0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           2500        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "moves (Multiply)                (None, 50)           0           dense[0][0]                      \n",
      "                                                                 valid_moves[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 116,745\n",
      "Trainable params: 116,231\n",
      "Non-trainable params: 514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dqn.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dqn.load_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = tf.keras.models.clone_model(dqn)\n",
    "target_policy = tf.keras.models.clone_model(dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9djBWO1wJR1"
   },
   "source": [
    "### Initialization of models \n",
    "should be random if the models are fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(states, model):\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    valid_moves = 1 - invalid_moves\n",
    "    moves = model([states.astype(np.float32), valid_moves.astype(np.float32)])\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_values(states):\n",
    "    \"\"\"\n",
    "    Returns the action values of the states where invalid moves have -infinity value (minimum value of float32)\n",
    "    and valid moves have 0 value\n",
    "    \"\"\"\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    invalid_values = np.finfo(np.float32).min * invalid_moves\n",
    "    return invalid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_action_vals(states, actval_func):\n",
    "    '''\n",
    "    The maximum action value (including passing) given the states\n",
    "    '''\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, actval_func)\n",
    "    max_vals = tf.reduce_max(move_vals + invalid_values, axis=1)\n",
    "    return max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_action_vals(states, actval_func):\n",
    "    \"\"\"\n",
    "    Returns the moves that have the maximum values (including passing) given the states\n",
    "    \"\"\"\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, actval_func)\n",
    "    argmax_vals = tf.math.argmax(move_vals + invalid_values, axis=1)\n",
    "    \n",
    "    return argmax_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH4rDyuowJR3",
    "outputId": "6376f7a8-99ff-4352-e6fc-0eccd05dfa25",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def state_responses(states, taken_actions=None, next_states=None, rewards=None, terminals=None):\n",
    "    \"\"\"\n",
    "    Returns a figure of plots on the states and the models responses on those states\n",
    "    \"\"\"\n",
    "    state_values = max_action_vals(states, dqn)\n",
    "    move_values = feed_forward(states, dqn)\n",
    "    \n",
    "    if next_states is not None:\n",
    "        next_move_values = feed_forward(next_states, dqn)\n",
    "        next_state_values = max_action_vals(next_states, dqn)\n",
    "    else:\n",
    "        next_move_values = None\n",
    "        next_state_values = None\n",
    "        \n",
    "    num_states = states.shape[0]\n",
    "    num_cols = 2 if next_states is None else 4\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_cols * 3, num_states * 3))\n",
    "    for i in range(num_states):\n",
    "        plt.subplot(num_states,num_cols,1 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('Board')\n",
    "        plt.imshow(states[i][:,:,[0,1,3]].astype(np.float))\n",
    "\n",
    "        plt.subplot(num_states,num_cols,2 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                  .format(state_values[i], np.min(move_values[i][:-1]), \n",
    "                          np.max(move_values[i][:-1]), move_values[i][-1]))\n",
    "        plt.imshow(tf.reshape(move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "        \n",
    "        if next_states is not None:\n",
    "            assert taken_actions is not None and len(taken_actions) == len(next_states)\n",
    "            if i < next_states.shape[0]:\n",
    "                plt.subplot(num_states,num_cols, 3 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('Taken Action: {}\\n{}R {}T'.format(taken_actions[i], rewards[i], terminals[i]))\n",
    "                plt.imshow(next_states[i][:,:,[0,1,3]].astype(np.float))\n",
    "                \n",
    "                plt.subplot(num_states,num_cols,4 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                          .format(next_state_values[i], np.min(next_move_values[i][:-1]), \n",
    "                                  np.max(next_move_values[i][:-1]), next_move_values[i][-1]))\n",
    "                plt.imshow(tf.reshape(next_move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [],
   "source": [
    "state = go_env.reset()\n",
    "start_state = np.copy(state)\n",
    "state, reward, done, info = go_env.step((3,5))\n",
    "state, reward, done, info = go_env.step((5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJWxThQMwJRz"
   },
   "outputs": [],
   "source": [
    "states = state.transpose(1,2,0).reshape(1, BOARD_SIZE, BOARD_SIZE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(state_responses(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViUxxPnUwJR5"
   },
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 2000\n",
    "BATCH_SIZE = 256\n",
    "MAX_STEPS = 2 * BOARD_SIZE**2\n",
    "REPLAY_MEM_SIZE = 2e4\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "OPPONENT_UPDATE = 200\n",
    "\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 0.995\n",
    "EPSILON_MIN = 0.1\n",
    "\n",
    "GAMMA = 0.90\n",
    "TARGET_UPDATE = 1 # number of episodes to update the target critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([GAMMA**x for x in range(100)])\n",
    "plt.title(\"Gamma Powers\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sumB3IsFwJR6"
   },
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeB26mZvwJR7"
   },
   "outputs": [],
   "source": [
    "replay_mem = deque(maxlen=int(REPLAY_MEM_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for metric_key in ['loss', 'win_percentage']:\n",
    "    metrics[metric_key] = tf.keras.metrics.Mean('dqn_{}'.format(metric_key), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writers = {}\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "for summary_key in ['train', 'test']:\n",
    "    log_dir = 'logs/dqn/{}/{}'.format(current_time, summary_key)\n",
    "    summary_writers[summary_key] = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXOIVFjmwJR7"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_1d_to_2d(action_1d):\n",
    "    if action_1d == BOARD_SIZE**2:\n",
    "        action = None\n",
    "    else:\n",
    "        action = (action_1d // BOARD_SIZE, action_1d % BOARD_SIZE)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weighted_action(move_weights):\n",
    "    \"\"\"\n",
    "    Assumes all invalid moves have weight 0\n",
    "    \"\"\"\n",
    "    move_weights = preprocessing.normalize(move_weights, norm='l1')\n",
    "\n",
    "    if np.sum(move_weights) <= 0:\n",
    "        # Pass\n",
    "        return None\n",
    "    \n",
    "    action_1d = np.random.choice(np.arange(BOARD_SIZE**2 + 1), p=move_weights[0])\n",
    "    return convert_1d_to_2d(action_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(state):\n",
    "    \"\"\"\n",
    "    Assumed to be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    \"\"\"\n",
    "    invalid_moves = state[:,:,2].reshape((1,-1))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    move_weights = 1 - invalid_moves\n",
    "\n",
    "    action = random_weighted_action(move_weights)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(policy, state, epsilon):\n",
    "    \"\"\"\n",
    "    Gets an action based on exploration/exploitation\n",
    "    \"\"\"\n",
    "    if state.shape[0] == 4:\n",
    "        # State shape will be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "        state = state.transpose(1,2,0)\n",
    "            \n",
    "    epsilon_choice = np.random.uniform()\n",
    "    if epsilon_choice < epsilon:\n",
    "        # Random move\n",
    "        logging.debug(\"Exploring a random move\")\n",
    "        action = random_action(state)\n",
    "        \n",
    "    else:\n",
    "        # policy makes a move\n",
    "        logging.debug(\"Exploiting policy's move\")\n",
    "        reshaped_state = state.reshape(1, BOARD_SIZE, BOARD_SIZE, 4).astype(np.float32)\n",
    "        \n",
    "        flattened_actions = argmax_action_vals(reshaped_state, policy)\n",
    "        action_1d = actions[0]\n",
    "        action = convert_1d_to_2d(action_1d)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_for_action(move_values, actions):\n",
    "    '''\n",
    "    Get value from board_values based on action, or take the passing_values if the action is None\n",
    "    '''\n",
    "    action_values = tf.gather_nd(move_values, [(i, a[0] * BOARD_SIZE + a[1]) if a is not None \n",
    "                                                    else (i, BOARD_SIZE**2) \n",
    "                                                    for i, a in enumerate(actions)])\n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_obs(size=BATCH_SIZE):\n",
    "    '''\n",
    "    Get a batch of orig_states, actions, states, rewards, terminals as np array out of replay memory\n",
    "    '''\n",
    "    \n",
    "    # States were (BATCH_SIZE, 4, BOARD_SIZE, BOARD_SIZE)\n",
    "    # Convert them to (BATCH_SIZE, BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    batch = random.sample(replay_mem, size)\n",
    "    batch = list(zip(*batch))\n",
    "    orig_states = np.array(list(batch[0]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    actions = np.array(list(batch[1]))\n",
    "    states = np.array(list(batch[2]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    rewards = np.array(list(batch[3]), dtype=np.float32)\n",
    "    terminals = np.array(list(batch[4]), dtype=np.uint8)\n",
    "    \n",
    "    return orig_states, actions, states, rewards, terminals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_heatmaps():\n",
    "    num_samples = 3\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs(num_samples)\n",
    "    states = np.concatenate([states, start_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "    fig = state_responses(states, actions, next_states, rewards, terminals)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error = tf.keras.losses.MeanSquaredError(reduction=tf.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8QseVrawJR8"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "def update_dqn():\n",
    "    \"\"\"\n",
    "    Optimizes the critic in one step and updates the critic loss metric\n",
    "    \"\"\"\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs()\n",
    "    \n",
    "    # get values for next state\n",
    "    next_state_vals = max_action_vals(next_states, target_policy)\n",
    "    \n",
    "    batch_size = states.shape[0]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        move_vals = feed_forward(states, dqn)\n",
    "        action_vals = get_value_for_action(move_vals, actions)\n",
    "        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
    "    \n",
    "    metrics['loss'](val_loss)\n",
    "    \n",
    "    # compute and apply gradients\n",
    "    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0E04emPwJR-"
   },
   "outputs": [],
   "source": [
    "def play_a_game(episode, train, opponent_epsilon=0):\n",
    "    \"\"\"\n",
    "    Plays out a game, and iteratively updates the models at each step\n",
    "    Returns the number of moves by the end of the game and the list \n",
    "    of rewards after every turn by the black player\n",
    "    \"\"\"\n",
    "    global EPSILON\n",
    "    \n",
    "    # Basic setup\n",
    "    done = False\n",
    "    num_of_turns = 0\n",
    "    state = go_env.reset()\n",
    "    rewards = []\n",
    "    \n",
    "    while not done and num_of_turns <= MAX_STEPS:\n",
    "        # Copy state for memory\n",
    "        orig_state = np.copy(state)\n",
    "        \n",
    "        black_action = get_action(dqn, state, EPSILON)\n",
    "        if black_action is None:\n",
    "            logging.debug(\"Black (actor) passed\")\n",
    "            \n",
    "        state, reward, done, info = go_env.step(black_action)\n",
    "        num_of_turns += 1\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Update the critic and then actor if we are training and have enough events\n",
    "        if train and len(replay_mem) >= BATCH_SIZE:\n",
    "            update_dqn()        \n",
    "    \n",
    "            # Update exploration/exploitation\n",
    "            if EPSILON > EPSILON_MIN:\n",
    "                EPSILON *= EPSILON_DECAY\n",
    "                logging.debug(\"Epsilon decayed to {}\".format(EPSILON))\n",
    "            \n",
    "        if done:\n",
    "            # Add to memory if training\n",
    "            if train:\n",
    "                replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "            break\n",
    "            \n",
    "        # opponent makes a move\n",
    "        # swap the black and white layers\n",
    "        temp = np.copy(state[0])\n",
    "        state[0] = state[1]\n",
    "        state[1] = temp\n",
    "        # get action from opponent\n",
    "        white_action = get_action(None, state, epsilon=opponent_epsilon)\n",
    "        if white_action is None:\n",
    "            logging.debug(\"White (opponent) passed\")\n",
    "\n",
    "        state, reward, done, info = go_env.step(white_action)\n",
    "        \n",
    "        # Add to memory if training\n",
    "        if train:\n",
    "            replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "        \n",
    "        num_of_turns += 1\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    # Game ended\n",
    "    return num_of_turns, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:07<49:53,  1.50s/it]"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(NUM_EPISODES)):\n",
    "    # Reset all metrics\n",
    "    for metric in metrics.values():\n",
    "        metric.reset_states()\n",
    "        \n",
    "    # Update other models if appropriate\n",
    "    dqn.save_weights('tmp/dqn.h5')\n",
    "    if episode % OPPONENT_UPDATE == 0:\n",
    "        opponent.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated opponent\")\n",
    "        \n",
    "    if episode % TARGET_UPDATE == 0:\n",
    "        target_policy.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated policy\")\n",
    "        \n",
    "    # Train\n",
    "    num_turns, rewards = play_a_game(episode, train=True, opponent_epsilon=1)\n",
    "    \n",
    "    # Plot samples of states and response heatmaps\n",
    "    fig = sample_heatmaps()\n",
    "    \n",
    "    # log results\n",
    "    with summary_writers['train'].as_default():\n",
    "        tf.summary.image(\"model heat maps\", plot_to_image(fig), step=episode)\n",
    "        \n",
    "        tf.summary.scalar('last rewards', rewards[-1], step=episode)\n",
    "        tf.summary.scalar('number of moves', num_turns, step=episode)\n",
    "        tf.summary.scalar('loss', metrics['loss'].result(), step=episode)\n",
    "        tf.summary.scalar('epsilon', EPSILON, step=episode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get win percentage from 100 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_against_random_opponent():\n",
    "    wins = []\n",
    "    for _ in tqdm(range(100)):\n",
    "        num_moves, rewards = play_a_game(episode=None, train=False, opponent_epsilon=1)\n",
    "        win = rewards[-1]\n",
    "        wins.append(win)\n",
    "    return np.average(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_against_random_opponent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test against a pretrained AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA",
    "outputId": "4d6aa1e6-8b63-4a39-b600-e331284ad6ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S')\n",
    "\n",
    "state = go_env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    go_env.render()\n",
    "    \n",
    "    # Actor's move\n",
    "    action = get_action(dqn, state, epsilon=0)\n",
    "    \n",
    "    state, reward, done, info = go_env.step(action)\n",
    "    \n",
    "    go_env.render()\n",
    "    \n",
    "    # Player's move\n",
    "    player_moved = False\n",
    "    while not player_moved:\n",
    "        coords = input(\"Enter coordinates separated by space (`q` to quit)\\n\")\n",
    "        if coords == 'q':\n",
    "            done = True\n",
    "            break\n",
    "        coords = coords.split()\n",
    "        try:\n",
    "            row = int(coords[0])\n",
    "            col = int(coords[1])\n",
    "            print(row, col)\n",
    "            state, reward, done, info = go_env.step((row, col))\n",
    "            player_moved = True\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "go_ai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
