{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import itertools\n",
    "from go_ai import data, metrics, mcts, models\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "logging._warn_preinit_stderr = 0\n",
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 128\n",
    "MAX_STEPS = 2 * BOARD_SIZE**2\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EVAL_GAMES = 32\n",
    "ITERATIONS_PER_EVAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_SIMS = 0\n",
    "TEMP_FUNC = lambda x: 1/16 if x < 4 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR = 'model_weights/'\n",
    "ACTOR_CRITIC_PATH = WEIGHTS_DIR + 'actor_critic.h5'\n",
    "LOAD_SAVED_MODELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board with heuristic reward for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc1lqGjPwJRm"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_metrics = {}\n",
    "for metric_key in ['val_loss', 'overall_loss', 'num_steps', 'move_loss']:\n",
    "    tb_metrics[metric_key] = tf.keras.metrics.Mean('{}'.format(metric_key), dtype=tf.float32)\n",
    "tb_metrics['pred_win_acc'] = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/actor_critic/{}/main'.format(current_time)\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7ZoRfzIwJRr"
   },
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actor_critic = models.make_actor_critic(BOARD_SIZE, 'val_net', 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mct_forward = models.make_mcts_forward(actor_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = tf.keras.utils.plot_model(actor_critic, to_file='logs/model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"actor_critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 5, 5, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 5, 5, 64)     3520        board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 5, 5, 64)     256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 5, 5, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 5, 5, 64)     36928       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 5, 5, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 5, 5, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 5, 2)      130         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 5, 5, 2)      8           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 2)      130         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 5, 5, 2)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5, 5, 2)      8           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 50)           0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 5, 5, 2)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 26)           1326        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "invalid_values (InputLayer)     [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50)           0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 26)           0           dense[0][0]                      \n",
      "                                                                 invalid_values[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 26)           1326        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "move_probs (Softmax)            (None, 26)           0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            27          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,915\n",
      "Trainable params: 43,651\n",
      "Non-trainable params: 264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor_critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = tf.keras.models.clone_model(actor_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED_MODELS:\n",
    "    actor_critic.load_weights(ACTOR_CRITIC_PATH)\n",
    "    opponent.load_weights(ACTOR_CRITIC_PATH)\n",
    "    logging.info(\"Loaded saved models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.plot_symmetries(go_env, actor_critic, 'logs/symmetries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a whole game trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 35 ms, total: 1.46 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "traj, _ = data.self_play(go_env, policy=actor_critic, max_steps=MAX_STEPS, mc_sims=MC_SIMS, \n",
    "                             temp_func=lambda x: 1, get_symmetries=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = metrics.gen_traj_fig(go_env, actor_critic, lambda x: 1, MAX_STEPS, MC_SIMS)\n",
    "fig.savefig('logs/a_trajectory.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic_opt = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "replay_mem = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bc4f9f931e452da931ecf027aa9ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=256, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366b0b6ce4744822aabbe25d4b40fe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Episode', max=128, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    tqdm.write(\"Iteration {}\".format(iteration))\n",
    "    \n",
    "    # Train\n",
    "    logging.debug(\"Playing games\")\n",
    "    episode_pbar = tqdm(range(EPISODES_PER_ITERATION), desc='Self Play', leave=True, position=0)\n",
    "    for episode in episode_pbar:\n",
    "        trajectory, num_steps = data.self_play(go_env, policy=actor_critic, max_steps=MAX_STEPS, \n",
    "                                                       mc_sims=MC_SIMS, temp_func=TEMP_FUNC)\n",
    "\n",
    "        replay_mem.extend(trajectory)\n",
    "        tb_metrics['num_steps'].update_state(num_steps)\n",
    "        \n",
    "    # Update the models (also shuffles memory)\n",
    "    logging.debug(\"Updating model...\")\n",
    "    random.shuffle(replay_mem)\n",
    "    np_data = data.replay_mem_to_numpy(replay_mem)\n",
    "    batched_np_data = [np.array_split(datum, len(replay_mem) // BATCH_SIZE) for datum in np_data]\n",
    "    batched_mem = list(zip(*batched_np_data))\n",
    "    models.update_win_prediction(actor_critic, batched_mem, actor_critic_opt, iteration, tb_metrics)\n",
    "    \n",
    "    # Evaluate against previous model\n",
    "    if (iteration+1) % ITERATIONS_PER_EVAL == 0:\n",
    "        win_rate = metrics.evaluate(go_env, actor_critic, opponent, max_steps=MAX_STEPS, \n",
    "                                    num_games=NUM_EVAL_GAMES, mc_sims=MC_SIMS, temp_func=TEMP_FUNC)\n",
    "        if win_rate > 0.6:\n",
    "            actor_critic.save_weights(ACTOR_CRITIC_PATH)\n",
    "            opponent.load_weights(ACTOR_CRITIC_PATH)\n",
    "            logging.info(\"{:.1f}% Accepted new model\".format(100*win_rate))\n",
    "        else:\n",
    "            logging.info(\"{:.1f}% Rejected new model\".format(100*win_rate))\n",
    "    \n",
    "    # Log results and resets the metrics\n",
    "    logging.debug(\"Logging metrics to tensorboard...\")\n",
    "    metrics.log_to_tensorboard(summary_writer, tb_metrics, iteration, go_env, actor_critic)\n",
    "\n",
    "    # Reset memory\n",
    "    replay_mem.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA",
    "outputId": "4d6aa1e6-8b63-4a39-b600-e331284ad6ff",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)\n",
    "data.play_against(opponent, go_env, MC_SIMS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "go_ai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
