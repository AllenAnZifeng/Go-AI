{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "colab_type": "code",
    "id": "5YQ7bYMnwJRa",
    "outputId": "65617db9-e466-4ec7-d8e9-d829a89dc2a1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import random\n",
    "import itertools\n",
    "import go_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_AUGMENTATION = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 20000\n",
    "MAX_STEPS = 2 * BOARD_SIZE**2\n",
    "BATCH_SIZE = 1 * DATA_AUGMENTATION * MAX_STEPS\n",
    "REPLAY_MEM_SIZE = 1 * DATA_AUGMENTATION * MAX_STEPS\n",
    "\n",
    "ACTOR_LEARNING_RATE = 1e-4\n",
    "ACTOR_BETA_1 = 0.5\n",
    "CRITIC_LEARNING_RATE = 1e-3\n",
    "CRITIC_BETA_1 = 0.5\n",
    "\n",
    "EPSILON = 0.01\n",
    "EPSILON_DECAY = 0.99\n",
    "EPSILON_MIN = 0.01\n",
    "\n",
    "OPPONENT_UPDATE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board with heuristic reward for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -e gym-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S', reward_method='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_moves(states):\n",
    "    \"\"\"\n",
    "    Returns 1's where moves are invalid and 0's where moves are valid\n",
    "    \"\"\"\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,BOARD_SIZE**2))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    return invalid_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_values(states):\n",
    "    \"\"\"\n",
    "    Returns the action values of the states where invalid moves have -infinity value (minimum value of float32)\n",
    "    and valid moves have 0 value\n",
    "    \"\"\"\n",
    "    invalid_moves = get_invalid_moves(states)\n",
    "    invalid_values = np.finfo(np.float32).min * invalid_moves\n",
    "    return invalid_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sumB3IsFwJR6"
   },
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeB26mZvwJR7"
   },
   "outputs": [],
   "source": [
    "replay_mem = deque(maxlen=int(REPLAY_MEM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontally_flip(state_or_action):\n",
    "    if isinstance(state_or_action, np.ndarray):\n",
    "        return np.flip(state_or_action, 2)\n",
    "    else:\n",
    "        if state_or_action == BOARD_SIZE**2:\n",
    "            return state_or_action\n",
    "        col = state_or_action % BOARD_SIZE\n",
    "        flipped_action = state_or_action - col + (BOARD_SIZE-1 - col)\n",
    "        return flipped_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertically_flip(state_or_action):\n",
    "    if isinstance(state_or_action, np.ndarray):\n",
    "        return np.flip(state_or_action, 1)\n",
    "    else:\n",
    "        if state_or_action == BOARD_SIZE**2:\n",
    "            return state_or_action\n",
    "        row = state_or_action // BOARD_SIZE\n",
    "        col = state_or_action % BOARD_SIZE\n",
    "        flipped_action = (BOARD_SIZE-1 - row) * BOARD_SIZE + col\n",
    "        return flipped_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_90(state_or_action):\n",
    "    if isinstance(state_or_action, np.ndarray):\n",
    "        return np.rot90(state_or_action, axes=(1,2))\n",
    "    else:\n",
    "        row = state_or_action // BOARD_SIZE\n",
    "        col = state_or_action % BOARD_SIZE\n",
    "        rotated_action = (BOARD_SIZE-1 - col) * BOARD_SIZE + row\n",
    "        return rotated_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_orientations(state_or_action):\n",
    "    orientations = []\n",
    "    \n",
    "    v_flip = vertically_flip(state_or_action)\n",
    "    h_flip = horizontally_flip(state_or_action)\n",
    "    \n",
    "    \n",
    "    rot_90 = rotate_90(state_or_action)\n",
    "    rot_180 = rotate_90(rot_90)\n",
    "    rot_270 = rotate_90(rot_180)\n",
    "    \n",
    "    x_flip = horizontally_flip(v_flip)\n",
    "    d_flip = horizontally_flip(rot_90)\n",
    "    m_flip = rotate_90(h_flip)\n",
    "    \n",
    "    # vertical, horizontal flip\n",
    "    orientations.append(v_flip)\n",
    "    orientations.append(h_flip)\n",
    "    \n",
    "    # Rotations\n",
    "    orientations.append(rot_90)\n",
    "    orientations.append(rot_270)\n",
    "    \n",
    "    # Diagonal and cross flip\n",
    "    orientations.append(d_flip)\n",
    "    orientations.append(x_flip)\n",
    "    \n",
    "    # Mirror and Identity\n",
    "    orientations.append(m_flip)\n",
    "    orientations.append(state_or_action)\n",
    "    \n",
    "    return orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_replay_mem(state, action_1d, next_state, reward, done):\n",
    "    \"\"\"\n",
    "    Adds original event, plus augmented versions of those events\n",
    "    \"\"\"\n",
    "    \n",
    "    for s, a, ns in list(zip(all_orientations(state), \n",
    "                             all_orientations(action_1d), \n",
    "                             all_orientations(next_state))):\n",
    "        replay_mem.append((s, a, ns, reward, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_obs(index=None, size=BATCH_SIZE):\n",
    "    '''\n",
    "    Get a batch of orig_states, actions, states, rewards, terminals as np array out of replay memory\n",
    "    '''\n",
    "    \n",
    "    # States were (BATCH_SIZE, 4, BOARD_SIZE, BOARD_SIZE)\n",
    "    # Convert them to (BATCH_SIZE, BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    if index is None:\n",
    "        batch = random.sample(replay_mem, size)\n",
    "    else:\n",
    "        batch = itertools.islice(replay_mem, index*BATCH_SIZE, (index+1)*BATCH_SIZE)\n",
    "    batch = list(zip(*batch))\n",
    "    states = np.array(list(batch[0]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    actions = np.array(list(batch[1]), dtype=np.int)\n",
    "    next_states = np.array(list(batch[2]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    rewards = np.array(list(batch[3]), dtype=np.float32).reshape((-1,))\n",
    "    terminals = np.array(list(batch[4]), dtype=np.uint8)\n",
    "    \n",
    "    return states, actions, next_states, rewards, terminals\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7ZoRfzIwJRr"
   },
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR_PATH = 'tmp/actor.h5'\n",
    "CRITIC_PATH = 'tmp/critic.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9wWb0HvwJRs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_actor_critic(mode):\n",
    "    inputs = layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 4), name=\"board\")\n",
    "    valid_inputs = layers.Input(shape=(BOARD_SIZE**2 + 1,), name=\"valid_moves\")\n",
    "    invalid_values = layers.Input(shape=(BOARD_SIZE**2 + 1,), name=\"invalid_values\")\n",
    "    \n",
    "    x = layers.Flatten()(inputs)\n",
    "    \n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    if mode == 'actor':\n",
    "        move_probs = layers.Dense(128)(x)\n",
    "        move_probs = layers.BatchNormalization()(move_probs)\n",
    "        move_probs = layers.ReLU()(move_probs)\n",
    "        move_probs = layers.Dense(50)(move_probs)\n",
    "        move_probs = layers.BatchNormalization()(move_probs)\n",
    "        move_probs = layers.ReLU()(move_probs)\n",
    "        move_probs = layers.Add()([move_probs, invalid_values])\n",
    "        move_probs = layers.Softmax(name=\"move_probs\")(move_probs)\n",
    "        out = move_probs\n",
    "    else:\n",
    "        move_vals = layers.Dense(128)(x)\n",
    "        move_vals = layers.BatchNormalization()(move_vals)\n",
    "        move_vals = layers.ReLU()(move_vals)\n",
    "        move_vals = layers.Dense(50, activation=\"tanh\")(move_vals)\n",
    "        move_vals = layers.Multiply(name=\"move_vals\")([move_vals, valid_inputs])\n",
    "        out = move_vals\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, valid_inputs, invalid_values], \n",
    "                           outputs=out, name=mode)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actor = make_actor_critic('actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"actor\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 7, 7, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 196)          0           board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          50432       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 256)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          131584      re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           6450        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50)           200         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 50)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "invalid_values (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 50)           0           re_lu_5[0][0]                    \n",
      "                                                                 invalid_values[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "move_probs (Softmax)            (None, 50)           0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 622,202\n",
      "Trainable params: 618,774\n",
      "Non-trainable params: 3,428\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = make_actor_critic('critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 7, 7, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 196)          0           board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          50432       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          131584      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512)          2048        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 512)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 512)          2048        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 512)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 256)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          32896       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 128)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 50)           6450        re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "invalid_values (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "move_vals (Multiply)            (None, 50)           0           dense_11[0][0]                   \n",
      "                                                                 valid_moves[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 622,002\n",
      "Trainable params: 618,674\n",
      "Non-trainable params: 3,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.load_weights(ACTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.load_weights(CRITIC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = tf.keras.models.clone_model(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent.load_weights(ACTOR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9djBWO1wJR1"
   },
   "source": [
    "### Initialization of models \n",
    "should be random if the models are fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(states, network):\n",
    "    \"\"\"\n",
    "    Since the neural nets take in more than one parameter, \n",
    "    this functions serves as a wrapper to forward pass the data through the networks\n",
    "    \"\"\"\n",
    "    invalid_moves = get_invalid_moves(states)\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    valid_moves = 1 - invalid_moves\n",
    "    return network([states.astype(np.float32), \n",
    "                    valid_moves.astype(np.float32), \n",
    "                    invalid_values.astype(np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_move_distr(title, move_distr, scalar=None):\n",
    "    plt.axis('off')\n",
    "    plt.title('{} {:.1f}\\n{:.1f}L {:.1f}H {:.1f}P'\n",
    "              .format(title, 0 if scalar is None else scalar, \n",
    "                      np.min(move_distr[:-1]), np.max(move_distr[:-1]), \n",
    "                      move_distr[-1].numpy()))\n",
    "    plt.imshow(tf.reshape(move_distr[:-1], (BOARD_SIZE, BOARD_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH4rDyuowJR3",
    "outputId": "6376f7a8-99ff-4352-e6fc-0eccd05dfa25",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def state_responses(states, taken_actions, next_states, rewards, terminals):\n",
    "    \"\"\"\n",
    "    Returns a figure of plots on the states and the models responses on those states\n",
    "    \"\"\"\n",
    "    move_probs = forward_pass(states, actor)\n",
    "    move_vals = forward_pass(states, critic)\n",
    "    state_vals = tf.reduce_sum(move_probs * move_vals, axis=1)\n",
    "    \n",
    "    num_states = states.shape[0]\n",
    "    num_cols =4\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_cols * 2.5, num_states * 2))\n",
    "    for i in range(num_states):\n",
    "        plt.subplot(num_states,num_cols,1 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('Board')\n",
    "        plt.imshow(states[i][:,:,[0,1,3]].astype(np.float))\n",
    "        \n",
    "        plt.subplot(num_states,num_cols, 2 + num_cols*i)\n",
    "        plot_move_distr('Critic', 100 * move_vals[i], scalar=100 * state_vals[i].numpy())\n",
    "\n",
    "        plt.subplot(num_states,num_cols, 3 + num_cols*i)\n",
    "        plot_move_distr('Actor', 100 * move_probs[i], scalar=None)\n",
    "        \n",
    "        plt.subplot(num_states,num_cols, 4 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('Taken Action: {}\\n{:.0f}R {}T'\n",
    "                  .format(go_util.action_1d_to_2d(taken_actions[i], BOARD_SIZE), \n",
    "                                                         rewards[i], terminals[i]))\n",
    "        plt.imshow(next_states[i][:,:,[0,1,3]].astype(np.float))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_heatmaps(num_samples=2):\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs(size=num_samples)\n",
    "    \n",
    "    # Add latest terminal state\n",
    "    for (state, action, next_state, reward, terminal) in reversed(replay_mem):\n",
    "        if terminal:\n",
    "            states = np.concatenate([states, state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            actions = np.append(actions, action)\n",
    "            next_states = np.concatenate([next_states, next_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            rewards = np.append(rewards, reward)\n",
    "            terminals = np.append(terminals, terminal)\n",
    "            break\n",
    "    # Add latest start state\n",
    "    for (state, action, next_state, reward, terminal) in reversed(replay_mem):\n",
    "        if np.sum(state[:2]) == 0:\n",
    "            states = np.concatenate([states, state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            actions = np.append(actions, action)\n",
    "            next_states = np.concatenate([next_states, next_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            rewards = np.append(rewards, reward)\n",
    "            terminals = np.append(terminals, terminal)\n",
    "            break\n",
    "\n",
    "    fig = state_responses(states, actions, next_states, rewards, terminals)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [],
   "source": [
    "state = go_env.reset()\n",
    "first_action = (2,5)\n",
    "second_action = (5,2)\n",
    "first_state, reward, done, info = go_env.step(first_action)\n",
    "second_state, reward, done, info = go_env.step(second_action)\n",
    "add_to_replay_mem(state, go_util.action_2d_to_1d(first_action, BOARD_SIZE), second_state, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d216d036bd45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_heatmaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \"\"\"\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/huangeddie/Library/Python/3.7/lib/python/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2057\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 532\u001b[0;31m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plt.show(sample_heatmaps(num_samples=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_mem.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViUxxPnUwJR5"
   },
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc1lqGjPwJRm"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for metric_key in ['val_loss', 'move_loss']:\n",
    "    metrics[metric_key] = tf.keras.metrics.Mean('{}'.format(metric_key), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writers = {}\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "for summary_key in ['train', 'test']:\n",
    "    log_dir = 'logs/actor_critic/{}/{}'.format(current_time, summary_key)\n",
    "    summary_writers[summary_key] = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_tensorboard(episode):\n",
    "    with summary_writers['train'].as_default():\n",
    "        tf.summary.scalar('won', won.item(), step=episode)\n",
    "        tf.summary.scalar('number of moves', num_steps, step=episode)\n",
    "        tf.summary.scalar('val_loss', metrics['val_loss'].result(), step=episode)\n",
    "        tf.summary.scalar('move_loss', metrics['move_loss'].result(), step=episode)\n",
    "        tf.summary.scalar('epsilon', EPSILON, step=episode)\n",
    "        \n",
    "        # Plot samples of states and response heatmaps every so often\n",
    "        if episode % 32 == 0:\n",
    "            logging.debug(\"Sampling heatmaps...\")\n",
    "            fig = sample_heatmaps()\n",
    "            tf.summary.image(\"model heat maps\", plot_to_image(fig), step=episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXOIVFjmwJR7"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weighted_action(move_weights):\n",
    "    \"\"\"\n",
    "    Assumes all invalid moves have weight 0\n",
    "    Action is 1D\n",
    "    \"\"\"\n",
    "    move_weights = preprocessing.normalize(move_weights, norm='l1')\n",
    "\n",
    "    if np.sum(move_weights) <= 0:\n",
    "        # Pass\n",
    "        return None\n",
    "    \n",
    "    return np.random.choice(np.arange(BOARD_SIZE**2 + 1), p=move_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(state):\n",
    "    \"\"\"\n",
    "    Assumed to be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    Action is 1D\n",
    "    \"\"\"\n",
    "    invalid_moves = state[:,:,2].reshape((1,-1))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    move_weights = 1 - invalid_moves\n",
    "\n",
    "    return random_weighted_action(move_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(policy, state, epsilon):\n",
    "    \"\"\"\n",
    "    Gets an action (1D) based on exploration/exploitation\n",
    "    \"\"\"\n",
    "    if state.shape[0] == 4:\n",
    "        # State shape will be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "        state = state.transpose(1,2,0)\n",
    "            \n",
    "    epsilon_choice = np.random.uniform()\n",
    "    if epsilon_choice < epsilon:\n",
    "        # Random move\n",
    "        logging.debug(\"Exploring a random move\")\n",
    "        action = random_action(state)\n",
    "        \n",
    "    else:\n",
    "        # policy makes a move\n",
    "        logging.debug(\"Exploiting policy's move\")\n",
    "        reshaped_state = state.reshape(1, BOARD_SIZE, BOARD_SIZE, 4).astype(np.float32)\n",
    "        \n",
    "        move_probs = forward_pass(reshaped_state, policy)\n",
    "        action = random_weighted_action(move_probs)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_for_action(move_val_distrs, actions):\n",
    "    '''\n",
    "    Actions should be a one hot array [batch size, ] array\n",
    "    Get value from board_values based on action, or take the passing_values if the action is None\n",
    "    '''\n",
    "    one_hot_actions = tf.one_hot(actions, depth=BOARD_SIZE**2+1)\n",
    "    assert move_val_distrs.shape == one_hot_actions.shape\n",
    "    one_hot_move_values = move_val_distrs * one_hot_actions\n",
    "    move_values = tf.reduce_sum(one_hot_move_values, axis=1)\n",
    "    return move_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error = tf.keras.losses.MeanSquaredError(reduction=tf.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8QseVrawJR8"
   },
   "outputs": [],
   "source": [
    "actor_opt = tf.keras.optimizers.Adam(ACTOR_LEARNING_RATE, ACTOR_BETA_1)\n",
    "def update_actor():\n",
    "    \"\"\"\n",
    "    Optimizes the actor over the whole replay memory\n",
    "    \"\"\"\n",
    "    if len(replay_mem) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_indices = np.arange(len(replay_mem) // BATCH_SIZE)\n",
    "    np.random.shuffle(batch_indices)\n",
    "    \n",
    "    for batch_idx in batch_indices:\n",
    "        states, actions, next_states, winners, terminals = get_batch_obs(index=batch_idx)\n",
    "        batch_size = states.shape[0]\n",
    "        \n",
    "        # Actor\n",
    "        state_val_distrs = forward_pass(states, critic)\n",
    "        disavntg_val_distrs = tf.reduce_max(state_val_distrs, axis=1, keepdims=True) - state_val_distrs\n",
    "        with tf.GradientTape() as tape:    \n",
    "            move_prob_distrs = forward_pass(states, actor)\n",
    "            assert move_prob_distrs.shape == disavntg_val_distrs.shape\n",
    "            move_loss = (tf.reduce_sum(disavntg_val_distrs * move_prob_distrs) + \n",
    "                         0.1 * tf.reduce_sum(move_prob_distrs**2)) / batch_size\n",
    "        \n",
    "        metrics['move_loss'].update_state(move_loss)\n",
    "        \n",
    "        # compute and apply gradients\n",
    "        gradients = tape.gradient(move_loss, actor.trainable_variables)\n",
    "        actor_opt.apply_gradients(zip(gradients, actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_opt = tf.keras.optimizers.Adam(CRITIC_LEARNING_RATE, CRITIC_BETA_1)\n",
    "def update_critic():\n",
    "    \"\"\"\n",
    "    Optimizes the critic over the whole replay memory\n",
    "    \"\"\"\n",
    "    if len(replay_mem) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch_indices = np.arange(len(replay_mem) // BATCH_SIZE)\n",
    "    np.random.shuffle(batch_indices)\n",
    "    \n",
    "    for batch_idx in batch_indices:\n",
    "        states, actions, next_states, winners, terminals = get_batch_obs(index=batch_idx)\n",
    "        batch_size = states.shape[0]\n",
    "        \n",
    "        # Critic\n",
    "        with tf.GradientTape() as tape:\n",
    "            move_val_distrs = forward_pass(states, critic)\n",
    "            move_vals = get_value_for_action(move_val_distrs, actions)\n",
    "            assert winners.shape == move_vals.shape\n",
    "            val_loss = mean_squared_error(winners, move_vals) / batch_size\n",
    "        \n",
    "        metrics['val_loss'].update_state(val_loss)\n",
    "        \n",
    "        # compute and apply gradients\n",
    "        gradients = tape.gradient(val_loss, critic.trainable_variables)\n",
    "        critic_opt.apply_gradients(zip(gradients, critic.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0E04emPwJR-"
   },
   "outputs": [],
   "source": [
    "def play_a_game(episode, train, black_epsilon, white_epsilon):\n",
    "    \"\"\"\n",
    "    Plays out a game, and iteratively updates the models at each step\n",
    "    Returns the number of moves by the end of the game and the list \n",
    "    of rewards after every turn by the black player\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic setup\n",
    "    done = False\n",
    "    num_steps = 0\n",
    "    state = go_env.reset()\n",
    "    \n",
    "    # Make it a numpy array so it can be passed to the replay memory by reference\n",
    "    # That way, all events of the same game will have the same reward\n",
    "    win = np.zeros(1)\n",
    "    \n",
    "    while True:\n",
    "        # Black's move\n",
    "        black_action = get_action(actor, state, epsilon=black_epsilon)            \n",
    "        next_state, reward, done, info = go_env.step(go_util.action_1d_to_2d(black_action, \n",
    "                                                                             BOARD_SIZE))\n",
    "        num_steps += 1      \n",
    "            \n",
    "        if num_steps >= MAX_STEPS:\n",
    "            # Max number of steps. End game\n",
    "            reward = 1 if info['area']['b'] > info['area']['w'] else -1\n",
    "            done = True\n",
    "        if done:\n",
    "            # Set the winner if we're done\n",
    "            win[0] = reward\n",
    "            if train:\n",
    "                # Add to memory if training \n",
    "                # (black ended the game by making the last pass OR we hit the max number of steps)\n",
    "                add_to_replay_mem(state, black_action, next_state, win, done)\n",
    "            break\n",
    "            \n",
    "        # White's move\n",
    "        # Swapped white and black channels\n",
    "        white_action = get_action(opponent, next_state[[1,0,2,3]], epsilon=white_epsilon)\n",
    "        next_state, reward, done, info = go_env.step(go_util.action_1d_to_2d(white_action, \n",
    "                                                                             BOARD_SIZE))\n",
    "        num_steps += 1\n",
    "        \n",
    "        if num_steps >= MAX_STEPS:\n",
    "            # Max number of steps. End game\n",
    "            reward = 1 if info['area']['b'] > info['area']['w'] else -1\n",
    "            done = True\n",
    "        if train:\n",
    "            # Add to memory if training\n",
    "            add_to_replay_mem(state, black_action, next_state, win, done)\n",
    "        if done:\n",
    "            # Set the winner if we're done\n",
    "            win[0] = reward\n",
    "            break\n",
    "            \n",
    "        state = next_state\n",
    "    \n",
    "    # Game ended\n",
    "    return num_steps, win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for episode in tqdm(range(NUM_EPISODES)):\n",
    "    # Update other models if appropriate\n",
    "    logging.debug(\"Saving weights...\")\n",
    "    actor.save_weights(ACTOR_PATH)\n",
    "    critic.save_weights(CRITIC_PATH)\n",
    "    \n",
    "    if episode % OPPONENT_UPDATE == 0:\n",
    "        opponent.load_weights(ACTOR_PATH)\n",
    "        \n",
    "    # Train\n",
    "    logging.debug(\"Playing a game...\")\n",
    "    num_steps, won = play_a_game(episode, train=True, black_epsilon=EPSILON, \n",
    "                                 white_epsilon=EPSILON)\n",
    "    \n",
    "    # log results\n",
    "    logging.debug(\"Logging metrics to tensorboard...\")\n",
    "    log_to_tensorboard(episode)\n",
    "    \n",
    "    # Reset all metrics\n",
    "    logging.debug(\"Resetting metrics...\")\n",
    "    for metric in metrics.values():\n",
    "        metric.reset_states()\n",
    "    \n",
    "    # Update the model\n",
    "    logging.debug(\"Updating model...\")\n",
    "    update_critic()\n",
    "    update_actor()  \n",
    "    \n",
    "    # Update exploration/exploitation\n",
    "    if EPSILON > EPSILON_MIN:\n",
    "        EPSILON *= EPSILON_DECAY\n",
    "        logging.debug(\"Epsilon decayed to {}\".format(EPSILON))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get win percentage from 200 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_against_random_opponent():\n",
    "    wins = []\n",
    "    for _ in tqdm(range(200)):\n",
    "        num_moves, win = play_a_game(episode=None, \n",
    "                                         train=False, \n",
    "                                         black_epsilon=0, \n",
    "                                         white_epsilon=1)\n",
    "        wins.append(win)\n",
    "    return np.average(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_against_random_opponent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test against a pretrained AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA",
    "outputId": "4d6aa1e6-8b63-4a39-b600-e331284ad6ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S')\n",
    "\n",
    "state = go_env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    go_env.render()\n",
    "    \n",
    "    # Actor's move\n",
    "    action = get_action(actor, state, epsilon=0)\n",
    "    \n",
    "    state, reward, done, info = go_env.step(go_util.action_1d_to_2d(action, BOARD_SIZE))\n",
    "    \n",
    "    go_env.render()\n",
    "    \n",
    "    # Player's move\n",
    "    player_moved = False\n",
    "    while not player_moved:\n",
    "        coords = input(\"Enter coordinates separated by space (`q` to quit)\\n\")\n",
    "        if coords == 'q':\n",
    "            done = True\n",
    "            break\n",
    "        coords = coords.split()\n",
    "        try:\n",
    "            row = int(coords[0])\n",
    "            col = int(coords[1])\n",
    "            print(row, col)\n",
    "            state, reward, done, info = go_env.step((row, col))\n",
    "            player_moved = True\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "go_ai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
