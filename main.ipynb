{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from go_ai import data, metrics, policies\n",
    "from go_ai.models import value_model, actor_critic\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 256\n",
    "EPISODES_PER_ITERATION = 128\n",
    "NUM_EVAL_GAMES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TEMP = 1/64\n",
    "TEMP_DECAY = 0.9\n",
    "MIN_TEMP = 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8pWCj8jGa7Y"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODELS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers:  4\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 4 #mp.cpu_count() - 1\n",
    "print(\"Workers: \", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES_DIR = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfJcqNeEGa7b"
   },
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models/'\n",
    "CHECKPOINT_PATH = MODELS_DIR + 'checkpoint_{}x{}.h5'.format(BOARD_SIZE, BOARD_SIZE)\n",
    "TMP_MODEL_PATH = MODELS_DIR + 'tmp.h5'\n",
    "TMP_MCTS_PATH = MODELS_DIR + 'tmp_mcts.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_TRAJECTORY_PATH = 'logs/a_trajectory.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4m-C0k6Ga7q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from checkpoint\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 324,865\n",
      "Trainable params: 322,817\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if LOAD_SAVED_MODELS:\n",
    "    assert os.path.exists(CHECKPOINT_PATH)\n",
    "    print(\"Starting from checkpoint\")\n",
    "else:\n",
    "    val_net = value_model.make_model(BOARD_SIZE)\n",
    "    val_net.save(CHECKPOINT_PATH)\n",
    "    print(\"Initialized checkpoint and temp\") \n",
    "print()\n",
    "    \n",
    "# Sync temp with checkpoint\n",
    "shutil.copy(CHECKPOINT_PATH, TMP_MODEL_PATH)\n",
    "\n",
    "model = tf.keras.models.load_model(TMP_MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = actor_critic.make_model(BOARD_SIZE)\n",
    "actor_critic.save(TMP_MCTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_policy_args = policies.PolicyArgs('qtemp', BOARD_SIZE, TMP_MODEL_PATH, name='tmp', \n",
    "                                      temperature=INIT_TEMP)\n",
    "checkpoint_policy_args = policies.PolicyArgs('qtemp', BOARD_SIZE, CHECKPOINT_PATH, name='checkpoint', \n",
    "                                             temperature=INIT_TEMP)\n",
    "random_policy_args = policies.PolicyArgs('random', BOARD_SIZE)\n",
    "greedy_policy_args = policies.PolicyArgs('greedy', BOARD_SIZE)\n",
    "human_policy_args = policies.PolicyArgs('human', BOARD_SIZE)\n",
    "mcts_policy_args = policies.PolicyArgs('monte_carlo', BOARD_SIZE, TMP_MCTS_PATH, max_searches=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVCEKWx_Ga7r"
   },
   "source": [
    "# Demo and Time Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSQ1RFHuGa7r"
   },
   "source": [
    "Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 11 ms, total: 251 ms\n",
      "Wall time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_env.reset()\n",
    "action = (1, 1)\n",
    "next_state, _, _, _ = go_env.step(action)\n",
    "metrics.plot_symmetries(next_state, 'logs/symmetries.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode worker: 1it [00:00,  2.57it/s]\n",
      "tmp vs. tmp: 100%|██████████| 1/1 [00:00<00:00, 1095.40it/s, 0.0% WIN]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 41 ms, total: 1.85 s\n",
      "Wall time: 1.85 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data.make_episodes(tmp_policy_args, tmp_policy_args, 1, num_workers=1, \n",
    "                   outdir=EPISODES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrTjrYjBGa7u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.06 s, sys: 187 ms, total: 6.25 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fig = metrics.gen_traj_fig(go_env, tmp_policy_args)\n",
    "fig.savefig(DEMO_TRAJECTORY_PATH)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 671 ms, total: 11.3 s\n",
      "Wall time: 9.64 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1980x720 with 29 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "fig = metrics.gen_mct_plot(go_env, mcts_policy_args, max_layers=5, max_branch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_temps(policy_args_list, temp_decay, min_temp):\n",
    "    for policy_args in policy_args_list:\n",
    "        assert hasattr(policy_args, 'temperature')\n",
    "        policy_args.temperature *= temp_decay\n",
    "        if policy_args.temperature < min_temp:\n",
    "            policy_args.temperature = min_temp\n",
    "        print(f\"{policy_args.name} temperature decayed to {policy_args.temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_temps(policy_args_list, temp):\n",
    "    for policy_args in policy_args_list:\n",
    "        assert hasattr(policy_args, 'temperature')\n",
    "        policy_args.temperature = temp\n",
    "        print(f\"{policy_args.name} temperature set to {policy_args.temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "outputId": "100dda95-316e-457c-b1f3-c8bf82243c52",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:17<00:00,  7.35it/s, 59.0% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3471 samples\n",
      "3471/3471 [==============================] - 1s 272us/sample - loss: 0.6198 - binary_accuracy: 0.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:17<00:00,  7.20it/s, 46.5% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.5% Continuing to train current weights\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:15<00:00,  8.28it/s, 52.3% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2810 samples\n",
      "2810/2810 [==============================] - 1s 310us/sample - loss: 0.4172 - binary_accuracy: 0.8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:18<00:00,  7.03it/s, 56.2% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.2% Continuing to train current weights\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:17<00:00,  7.39it/s, 49.2% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3544 samples\n",
      "3544/3544 [==============================] - 1s 269us/sample - loss: 0.6513 - binary_accuracy: 0.6185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:17<00:00,  7.33it/s, 51.6% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.6% Continuing to train current weights\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:14<00:00,  9.09it/s, 57.8% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2517 samples\n",
      "2517/2517 [==============================] - 1s 468us/sample - loss: 0.4480 - binary_accuracy: 0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:18<00:00,  7.08it/s, 61.7% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.7% Accepted new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. random: 100%|██████████| 128/128 [00:09<00:00, 13.38it/s, 99.2% WIN]\n",
      "tmp vs. greedy: 100%|██████████| 128/128 [00:14<00:00,  8.67it/s, 80.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.1%G 99.2%R\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.96it/s, 47.7% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3233 samples\n",
      "3233/3233 [==============================] - 1s 282us/sample - loss: 0.4486 - binary_accuracy: 0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:17<00:00,  7.42it/s, 24.2% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2% Rejected new model\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.78it/s, 45.3% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3385 samples\n",
      "3385/3385 [==============================] - 1s 274us/sample - loss: 0.4335 - binary_accuracy: 0.7427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:16<00:00,  7.70it/s, 21.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1% Rejected new model\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.78it/s, 46.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3388 samples\n",
      "3388/3388 [==============================] - 1s 274us/sample - loss: 0.4344 - binary_accuracy: 0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:16<00:00,  7.72it/s, 14.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1% Rejected new model\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.58it/s, 56.2% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3386 samples\n",
      "3386/3386 [==============================] - 1s 275us/sample - loss: 0.4974 - binary_accuracy: 0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:16<00:00,  7.62it/s, 24.2% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2% Rejected new model\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.80it/s, 53.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3349 samples\n",
      "3349/3349 [==============================] - 1s 277us/sample - loss: 0.4997 - binary_accuracy: 0.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:16<00:00,  7.85it/s, 18.0% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0% Rejected new model\n",
      "tmp temperature decayed to 0.015625\n",
      "checkpoint temperature decayed to 0.015625\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. tmp: 100%|██████████| 128/128 [00:16<00:00,  7.58it/s, 53.1% WIN]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3428 samples\n",
      "3428/3428 [==============================] - 1s 274us/sample - loss: 0.4937 - binary_accuracy: 0.7039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp vs. checkpoint: 100%|██████████| 128/128 [00:18<00:00,  6.85it/s, 18.8% WIN]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-229d13d3cc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Evaluate against checkpoint model and other baselines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     opp_win_rate = data.make_episodes(tmp_policy_args, checkpoint_policy_args, \n\u001b[0;32m---> 15\u001b[0;31m                                       NUM_EVAL_GAMES, NUM_WORKERS)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopp_win_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Go-AI/go_ai/data.py\u001b[0m in \u001b[0;36mmake_episodes\u001b[0;34m(first_policy_args, second_policy_args, episodes, num_workers, outdir)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# Cleanup the workers if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Make and write out the episode data\n",
    "    data.make_episodes(tmp_policy_args, tmp_policy_args, EPISODES_PER_ITERATION, \n",
    "                       num_workers=NUM_WORKERS, outdir=EPISODES_DIR)\n",
    "    # Read in the episode data\n",
    "    replay_data = data.episodes_from_dir(EPISODES_DIR)\n",
    "\n",
    "    # Optimize\n",
    "    value_model.optimize(tmp_policy_args, replay_data, BATCH_SIZE)\n",
    "    \n",
    "    # Evaluate against checkpoint model and other baselines\n",
    "    opp_win_rate = data.make_episodes(tmp_policy_args, checkpoint_policy_args, \n",
    "                                      NUM_EVAL_GAMES, NUM_WORKERS)\n",
    "\n",
    "    if opp_win_rate > 0.6:\n",
    "        # New parameters are significantly better. Accept it\n",
    "        shutil.copy(TMP_MODEL_PATH, CHECKPOINT_PATH)\n",
    "        print(f\"{100*opp_win_rate:.1f}% Accepted new model\")\n",
    "        \n",
    "        rand_win_rate = data.make_episodes(tmp_policy_args, random_policy_args, \n",
    "                                           NUM_EVAL_GAMES, NUM_WORKERS)\n",
    "        greed_win_rate = data.make_episodes(tmp_policy_args, greedy_policy_args, \n",
    "                                            NUM_EVAL_GAMES, NUM_WORKERS)\n",
    "        print(f\"{100*greed_win_rate:.1f}%G {100*rand_win_rate:.1f}%R\")\n",
    "\n",
    "        # Plot samples of states and response heatmaps\n",
    "        fig = metrics.gen_traj_fig(go_env, tmp_policy_args)\n",
    "        fig.savefig(DEMO_TRAJECTORY_PATH)\n",
    "        plt.close()\n",
    "    elif opp_win_rate >= 0.4:\n",
    "        # New parameters are significantly worse. Reject it.\n",
    "        print(f\"{100*opp_win_rate:.1f}% Continuing to train current weights\")\n",
    "    else:\n",
    "        # Keep trying\n",
    "        shutil.copy(CHECKPOINT_PATH, TMP_MODEL_PATH)\n",
    "        print(f\"{100*opp_win_rate:.1f}% Rejected new model\")\n",
    "        \n",
    "    # Decay the temperatures if any\n",
    "    decay_temps([tmp_policy_args, checkpoint_policy_args], TEMP_DECAY, MIN_TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Moy9uJ6fGa7z"
   },
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_temps([tmp_policy_args, checkpoint_policy_args], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.make_episodes(greedy_policy_args, checkpoint_policy_args, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA"
   },
   "outputs": [],
   "source": [
    "data.make_episodes(checkpoint_policy_args, human_policy_args, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emKESg3hGa71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of go_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
